{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de399a6cba674bb59afc0f6741fdd7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_680144a3d559460db1cd633bc9e83ab4",
              "IPY_MODEL_b917ad74f03a4fc897a678b37dc992b1",
              "IPY_MODEL_bb40242536a2430a996166d63fb70d21"
            ],
            "layout": "IPY_MODEL_a0101392287e49d98281c2e0ed885790"
          }
        },
        "680144a3d559460db1cd633bc9e83ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f853601783848898c44a5a34d4e091b",
            "placeholder": "​",
            "style": "IPY_MODEL_10874f14c1c149e28adf7622b1d0879f",
            "value": "config.json: 100%"
          }
        },
        "b917ad74f03a4fc897a678b37dc992b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_728e1a55c81641d98f79240151626dcf",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32a43da0e6864c31b37a9b81a821d9f1",
            "value": 614
          }
        },
        "bb40242536a2430a996166d63fb70d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a413df1921b449668c6bc4533a8efad3",
            "placeholder": "​",
            "style": "IPY_MODEL_1cd7e035b98f4e508edc2de8584db8fe",
            "value": " 614/614 [00:00&lt;00:00, 37.6kB/s]"
          }
        },
        "a0101392287e49d98281c2e0ed885790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f853601783848898c44a5a34d4e091b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10874f14c1c149e28adf7622b1d0879f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "728e1a55c81641d98f79240151626dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32a43da0e6864c31b37a9b81a821d9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a413df1921b449668c6bc4533a8efad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cd7e035b98f4e508edc2de8584db8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74aa1e12c1a54fabb2a15ea423a271b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68f1ed72e3b24d7c91014932b933e53e",
              "IPY_MODEL_017c323842d444b0a1890f386f77e7c2",
              "IPY_MODEL_2d9207e8c4bc46e4839d835f5805c4fb"
            ],
            "layout": "IPY_MODEL_8607a4e547f347dca04a7b4abc13ad8f"
          }
        },
        "68f1ed72e3b24d7c91014932b933e53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9739700bac47bca5bb95c5e9c9a9d8",
            "placeholder": "​",
            "style": "IPY_MODEL_db58f0abed6e4534b3c1064ac808fa13",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "017c323842d444b0a1890f386f77e7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbbad5b04d71463ea2ed80a0db31d2c1",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06b6c50c482b4766897a6bc55e08137a",
            "value": 26788
          }
        },
        "2d9207e8c4bc46e4839d835f5805c4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a49302bb18fd4b87baae99b56273f9c5",
            "placeholder": "​",
            "style": "IPY_MODEL_c0924730a7304634877bff5c328a19c6",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.87MB/s]"
          }
        },
        "8607a4e547f347dca04a7b4abc13ad8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb9739700bac47bca5bb95c5e9c9a9d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db58f0abed6e4534b3c1064ac808fa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbbad5b04d71463ea2ed80a0db31d2c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06b6c50c482b4766897a6bc55e08137a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a49302bb18fd4b87baae99b56273f9c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0924730a7304634877bff5c328a19c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "534b4970f73d4f41b399e6860ecd5d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2800c6ddcba14a388540d038d9ebe3b3",
              "IPY_MODEL_dc8c8cb1100048a799836459e1e24c9b",
              "IPY_MODEL_b05587a6dca5441ba4761ea0dfa47482"
            ],
            "layout": "IPY_MODEL_f8a29890aa0642a7b409fd6a42016e3a"
          }
        },
        "2800c6ddcba14a388540d038d9ebe3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a2bd2c929344f7964c1841a3594bb1",
            "placeholder": "​",
            "style": "IPY_MODEL_1014241257804129b29985b2136e934b",
            "value": "Downloading shards: 100%"
          }
        },
        "dc8c8cb1100048a799836459e1e24c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f48bfe038b614f399959cec81998302a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91c91a94e2a4410a85732ce8b93e4a09",
            "value": 2
          }
        },
        "b05587a6dca5441ba4761ea0dfa47482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f472a4d6eab140059543028d65655286",
            "placeholder": "​",
            "style": "IPY_MODEL_678413217fe643d6a12451796d8d353d",
            "value": " 2/2 [02:00&lt;00:00, 54.26s/it]"
          }
        },
        "f8a29890aa0642a7b409fd6a42016e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a2bd2c929344f7964c1841a3594bb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1014241257804129b29985b2136e934b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f48bfe038b614f399959cec81998302a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c91a94e2a4410a85732ce8b93e4a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f472a4d6eab140059543028d65655286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "678413217fe643d6a12451796d8d353d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad0c6c2353fd4622bb2d9ef25db5f1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d91efaa66d784de29813c413c75db84b",
              "IPY_MODEL_ba8b3d5b1f1249008c81f2e2f41cc414",
              "IPY_MODEL_54eb08aebfdf4993bb76cda80bb22eab"
            ],
            "layout": "IPY_MODEL_e1631c625c4b4bd5b1d4277473301153"
          }
        },
        "d91efaa66d784de29813c413c75db84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a54133b4b4e40b6a6778003b1924ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_518f6e299b1b4b5f8932fd89f751970b",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "ba8b3d5b1f1249008c81f2e2f41cc414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b634e4b03d6649eba991c7ad83885ef6",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f45570dc9fc457fa340f6e23ad35050",
            "value": 9976576152
          }
        },
        "54eb08aebfdf4993bb76cda80bb22eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d86b90822b4f0887ed1e1b42ed8384",
            "placeholder": "​",
            "style": "IPY_MODEL_20be6e7471da4003a4a7e172c0deb575",
            "value": " 9.98G/9.98G [01:32&lt;00:00, 172MB/s]"
          }
        },
        "e1631c625c4b4bd5b1d4277473301153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a54133b4b4e40b6a6778003b1924ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518f6e299b1b4b5f8932fd89f751970b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b634e4b03d6649eba991c7ad83885ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f45570dc9fc457fa340f6e23ad35050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5d86b90822b4f0887ed1e1b42ed8384": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20be6e7471da4003a4a7e172c0deb575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73f930df3d7849029cf5aee69521abf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e569bb0c749439c8bbc6cc20b398523",
              "IPY_MODEL_d83598db074345a0871c1c15b3f4cd06",
              "IPY_MODEL_1b35db9614ed41e092ab7cf923df6b02"
            ],
            "layout": "IPY_MODEL_126544b500fa49a68ad7279f00f7fb8e"
          }
        },
        "7e569bb0c749439c8bbc6cc20b398523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db602f0c40dc42d5909131ac428a5afe",
            "placeholder": "​",
            "style": "IPY_MODEL_2e3f5a48f7394481bf5806fe0deb160c",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "d83598db074345a0871c1c15b3f4cd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62527da123f4eae9de6f5a283de7d6e",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a11a9ac9d04ca69b7555da8117f1bb",
            "value": 3500296424
          }
        },
        "1b35db9614ed41e092ab7cf923df6b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_283cc415a2004d4d9dbe581c24fb69f4",
            "placeholder": "​",
            "style": "IPY_MODEL_54698ad9566046148d8911e27ec7e770",
            "value": " 3.50G/3.50G [00:27&lt;00:00, 151MB/s]"
          }
        },
        "126544b500fa49a68ad7279f00f7fb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db602f0c40dc42d5909131ac428a5afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e3f5a48f7394481bf5806fe0deb160c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e62527da123f4eae9de6f5a283de7d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a11a9ac9d04ca69b7555da8117f1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "283cc415a2004d4d9dbe581c24fb69f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54698ad9566046148d8911e27ec7e770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deffb4e3d2464afab7e9de0903561688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2fcf6d71a4e4ffbad10bb2dc718218a",
              "IPY_MODEL_e3b628c4bc7c400caf5e5f79ac08d4b9",
              "IPY_MODEL_a78f52a2ccf04e718548360a554bc894"
            ],
            "layout": "IPY_MODEL_2853bd3d62414a49a26d11c0dd9f094b"
          }
        },
        "e2fcf6d71a4e4ffbad10bb2dc718218a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54d1113ce20148858ec3c575b9d5150d",
            "placeholder": "​",
            "style": "IPY_MODEL_83e9c74958ef458a878ac7694cbd568f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e3b628c4bc7c400caf5e5f79ac08d4b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a3713f77a646d19937129308ffb6d2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_922254dfdd8543aa8fc39474431f4d2d",
            "value": 2
          }
        },
        "a78f52a2ccf04e718548360a554bc894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d12a19245f84932a5d3af264a8ed41e",
            "placeholder": "​",
            "style": "IPY_MODEL_d44d4b4eadb74db0998a229e74b8eaec",
            "value": " 2/2 [00:58&lt;00:00, 26.55s/it]"
          }
        },
        "2853bd3d62414a49a26d11c0dd9f094b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d1113ce20148858ec3c575b9d5150d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e9c74958ef458a878ac7694cbd568f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80a3713f77a646d19937129308ffb6d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922254dfdd8543aa8fc39474431f4d2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d12a19245f84932a5d3af264a8ed41e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44d4b4eadb74db0998a229e74b8eaec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96bbd8087838489b8b1af943386e90a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ae0c617d58647ec9d06cdc0ae7b1970",
              "IPY_MODEL_3bc9359bffc941509d6b246ffd7042eb",
              "IPY_MODEL_1ce6f82add9c41668aadf8bedaed20ef"
            ],
            "layout": "IPY_MODEL_7b637d455b90415e964116e0558b853a"
          }
        },
        "4ae0c617d58647ec9d06cdc0ae7b1970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da71cbe6eb314708b14905a4493cde9f",
            "placeholder": "​",
            "style": "IPY_MODEL_477a87b2312c46b897f5b7ee00b2cbd1",
            "value": "generation_config.json: 100%"
          }
        },
        "3bc9359bffc941509d6b246ffd7042eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7eec731ed24473bc9388ef065885e0",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48512e4e784f456e9e4b70a865aed74f",
            "value": 188
          }
        },
        "1ce6f82add9c41668aadf8bedaed20ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dcd1b72cbe347b096dd002d1482d578",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e74a04cae942c586472d6cb8fd5c56",
            "value": " 188/188 [00:00&lt;00:00, 11.2kB/s]"
          }
        },
        "7b637d455b90415e964116e0558b853a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da71cbe6eb314708b14905a4493cde9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477a87b2312c46b897f5b7ee00b2cbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d7eec731ed24473bc9388ef065885e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48512e4e784f456e9e4b70a865aed74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dcd1b72cbe347b096dd002d1482d578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1e74a04cae942c586472d6cb8fd5c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "452084d132174bc3a752394aab247094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21286ffdeec84668b0d577f80ff9ca0b",
              "IPY_MODEL_50cd16b2b2b14a128506cf46aba1a5e2",
              "IPY_MODEL_20d113ad05ac489f980fc883fc28ceba"
            ],
            "layout": "IPY_MODEL_272dfb48b1984fb0ae40fc4d60f0153d"
          }
        },
        "21286ffdeec84668b0d577f80ff9ca0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e1ead30aa74e5b9a571e3bc653cfd7",
            "placeholder": "​",
            "style": "IPY_MODEL_534917c5ee4a4e73bf06d57ca8421ea0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "50cd16b2b2b14a128506cf46aba1a5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79936272eff841b79a582e0cfb8576ce",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_974972f126174be2964ccb8dc973bf74",
            "value": 1618
          }
        },
        "20d113ad05ac489f980fc883fc28ceba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb08032f66148398bc527181230b09b",
            "placeholder": "​",
            "style": "IPY_MODEL_a6ce20adf74a44049f0baa74ab8e0b4b",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 83.2kB/s]"
          }
        },
        "272dfb48b1984fb0ae40fc4d60f0153d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e1ead30aa74e5b9a571e3bc653cfd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "534917c5ee4a4e73bf06d57ca8421ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79936272eff841b79a582e0cfb8576ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "974972f126174be2964ccb8dc973bf74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddb08032f66148398bc527181230b09b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6ce20adf74a44049f0baa74ab8e0b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc5300ac2a641bfb0af35c0c88fb369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b71dbc6b2fc749fbae21c21ba9692747",
              "IPY_MODEL_79fd470180cf46ceb0f8dd0fac09a695",
              "IPY_MODEL_cd4dc0b201e14a71984eb2867a554c3c"
            ],
            "layout": "IPY_MODEL_0442d33020e94a35b197f7cff01d84e5"
          }
        },
        "b71dbc6b2fc749fbae21c21ba9692747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f561d767a64a441fa97a6d919b28dbe7",
            "placeholder": "​",
            "style": "IPY_MODEL_74ea1251252a44c8b2be486504e7e33a",
            "value": "tokenizer.model: 100%"
          }
        },
        "79fd470180cf46ceb0f8dd0fac09a695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd2b98fe37444f9a9e8973699426e035",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_317f6a4a34d84848af11381e3860ee81",
            "value": 499723
          }
        },
        "cd4dc0b201e14a71984eb2867a554c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a98913bfe104891bfdbc7b0ae0ea738",
            "placeholder": "​",
            "style": "IPY_MODEL_8439dd823b5a41ce8586a0feb29314c1",
            "value": " 500k/500k [00:00&lt;00:00, 33.7MB/s]"
          }
        },
        "0442d33020e94a35b197f7cff01d84e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f561d767a64a441fa97a6d919b28dbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74ea1251252a44c8b2be486504e7e33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2b98fe37444f9a9e8973699426e035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317f6a4a34d84848af11381e3860ee81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a98913bfe104891bfdbc7b0ae0ea738": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8439dd823b5a41ce8586a0feb29314c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ad2688f7a84251bc3464a5af4082c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68fcb5a41ca04414b3f80d447a0ca1e5",
              "IPY_MODEL_521e2d82af0944dbbe11ad06798e1c25",
              "IPY_MODEL_3cc44ba1d9bb4ffba9c1807e144c7764"
            ],
            "layout": "IPY_MODEL_d21f670ea40f4048a11d55c75b7b5c39"
          }
        },
        "68fcb5a41ca04414b3f80d447a0ca1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_088d2ced8591472ab8db9716cdc0a40b",
            "placeholder": "​",
            "style": "IPY_MODEL_9a12cb97b49147daa96847ad86718edc",
            "value": "tokenizer.json: 100%"
          }
        },
        "521e2d82af0944dbbe11ad06798e1c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4702b5ed833849c88a43bf8bba887165",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_565f8869e8c94697a55ea112ca6b4c8c",
            "value": 1842767
          }
        },
        "3cc44ba1d9bb4ffba9c1807e144c7764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce073da5ae147a6b409fcb6475347f3",
            "placeholder": "​",
            "style": "IPY_MODEL_278f4d2f89714725bf7480a6fd3d7112",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 20.9MB/s]"
          }
        },
        "d21f670ea40f4048a11d55c75b7b5c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088d2ced8591472ab8db9716cdc0a40b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a12cb97b49147daa96847ad86718edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4702b5ed833849c88a43bf8bba887165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "565f8869e8c94697a55ea112ca6b4c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ce073da5ae147a6b409fcb6475347f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278f4d2f89714725bf7480a6fd3d7112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e42ae020374240048e9c9437fec73b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a150c6b9ac994ae7bd644a8b6f316c1e",
              "IPY_MODEL_5d5d147750274c7dbbb8a9e4e6d75c45",
              "IPY_MODEL_4bd946625f3045af923cdcb9e6f32945"
            ],
            "layout": "IPY_MODEL_ababef2ce6544671aa53a33db2c91ab7"
          }
        },
        "a150c6b9ac994ae7bd644a8b6f316c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dd916c6d52c45058eb489a2a5c916ca",
            "placeholder": "​",
            "style": "IPY_MODEL_b7ad0d71e1eb4b7bbdc47d5e4dc0aceb",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5d5d147750274c7dbbb8a9e4e6d75c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b2db8a7363745ff98cc3945931971cc",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab8f0158c9404617bc95f8913ee1b6de",
            "value": 414
          }
        },
        "4bd946625f3045af923cdcb9e6f32945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f60855cdeec4d8e97a023faeef3e699",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe3477054dd48d7a6422a3a82dba648",
            "value": " 414/414 [00:00&lt;00:00, 30.9kB/s]"
          }
        },
        "ababef2ce6544671aa53a33db2c91ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd916c6d52c45058eb489a2a5c916ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ad0d71e1eb4b7bbdc47d5e4dc0aceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b2db8a7363745ff98cc3945931971cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8f0158c9404617bc95f8913ee1b6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f60855cdeec4d8e97a023faeef3e699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe3477054dd48d7a6422a3a82dba648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb53e553fc24f00bc1c40fb1fe92af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f47c1b60a8141d2b83cba704b582f28",
              "IPY_MODEL_700625e9fbf34fc3a4be0e1aca0f7b9e",
              "IPY_MODEL_8ef902858f2840848a386fdde9c549f4"
            ],
            "layout": "IPY_MODEL_8d52a8ef58204ab38c52502e0c5991ac"
          }
        },
        "2f47c1b60a8141d2b83cba704b582f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01815c9026444a44bbefce0fe267f19a",
            "placeholder": "​",
            "style": "IPY_MODEL_da39c542307c493c8d5fe2f0176f621e",
            "value": "modules.json: 100%"
          }
        },
        "700625e9fbf34fc3a4be0e1aca0f7b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c4d8b856d11497092eec506d29ad4b9",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d7e75958f82415c8e4315ad5c8d6467",
            "value": 349
          }
        },
        "8ef902858f2840848a386fdde9c549f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0a43a8adc14b9382056c542d47ac98",
            "placeholder": "​",
            "style": "IPY_MODEL_9ccab893491d4005ad3340cd0be4bd16",
            "value": " 349/349 [00:00&lt;00:00, 16.8kB/s]"
          }
        },
        "8d52a8ef58204ab38c52502e0c5991ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01815c9026444a44bbefce0fe267f19a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da39c542307c493c8d5fe2f0176f621e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c4d8b856d11497092eec506d29ad4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7e75958f82415c8e4315ad5c8d6467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a0a43a8adc14b9382056c542d47ac98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ccab893491d4005ad3340cd0be4bd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c38d42d62713431e9bba7321976fd18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd6f9459a2ce4dc9aeaebfee1430f538",
              "IPY_MODEL_9f5876b16b3d4237927293c6aa1c6da4",
              "IPY_MODEL_bde4106190a0456992c6a08a739e277f"
            ],
            "layout": "IPY_MODEL_cf1986b3024942f8a2a83c0797234d54"
          }
        },
        "bd6f9459a2ce4dc9aeaebfee1430f538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fecb87f3d3405da939727ba4f7c40a",
            "placeholder": "​",
            "style": "IPY_MODEL_747ef7faaabe44f1a041c883bf80ee3b",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "9f5876b16b3d4237927293c6aa1c6da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff464dd6e124d2fac0926704a380057",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f2ddc69003c43dbb22e65d5830178e9",
            "value": 116
          }
        },
        "bde4106190a0456992c6a08a739e277f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a248b8ac4934021a8eccc0ded7dffbc",
            "placeholder": "​",
            "style": "IPY_MODEL_9388eda4a9e84e168cf1259d44931647",
            "value": " 116/116 [00:00&lt;00:00, 5.47kB/s]"
          }
        },
        "cf1986b3024942f8a2a83c0797234d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fecb87f3d3405da939727ba4f7c40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "747ef7faaabe44f1a041c883bf80ee3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff464dd6e124d2fac0926704a380057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2ddc69003c43dbb22e65d5830178e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a248b8ac4934021a8eccc0ded7dffbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9388eda4a9e84e168cf1259d44931647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9209b0f270134ac0881bd9e1f81cdd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71e28164e7f349d3b1c468f5a333a0c7",
              "IPY_MODEL_fdad79c5e73644bda129a024ee2329c3",
              "IPY_MODEL_f5b83a80b0a64662a7300ea76892b6a4"
            ],
            "layout": "IPY_MODEL_3fb924fec95243949704e76a9dd71cb4"
          }
        },
        "71e28164e7f349d3b1c468f5a333a0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b48d118e15948a6bc3744d12d0fc296",
            "placeholder": "​",
            "style": "IPY_MODEL_8dce746006b04a029ea2f19897d501f5",
            "value": "README.md: 100%"
          }
        },
        "fdad79c5e73644bda129a024ee2329c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ea0f1345cd4007b43a602f9d3be86d",
            "max": 10571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_981893b157314816a8fab3fc7008b684",
            "value": 10571
          }
        },
        "f5b83a80b0a64662a7300ea76892b6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608c1ffbac514019b6a16eab857dfb79",
            "placeholder": "​",
            "style": "IPY_MODEL_7cb11490e47c495b886fb772da2beae9",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 673kB/s]"
          }
        },
        "3fb924fec95243949704e76a9dd71cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b48d118e15948a6bc3744d12d0fc296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dce746006b04a029ea2f19897d501f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58ea0f1345cd4007b43a602f9d3be86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981893b157314816a8fab3fc7008b684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "608c1ffbac514019b6a16eab857dfb79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb11490e47c495b886fb772da2beae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d1116535d2d4110a5dd1638d9dc51d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6ecc007721d4c3a81a801a43d7d3873",
              "IPY_MODEL_7d96895580de4cafa2e120420eb602de",
              "IPY_MODEL_c032324d38b9435d922880dceb2c0076"
            ],
            "layout": "IPY_MODEL_9815ba2b6f71456aa54dea35156d0499"
          }
        },
        "f6ecc007721d4c3a81a801a43d7d3873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e99fc049cd04717a3d07cdd86617709",
            "placeholder": "​",
            "style": "IPY_MODEL_1a7987542eb24e2fbebef9222ed91bf1",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "7d96895580de4cafa2e120420eb602de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c051adc33fbb46508ef3384243e0e7c0",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f0bd7ef23cd4af297acb371f2fad71d",
            "value": 53
          }
        },
        "c032324d38b9435d922880dceb2c0076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83e8dd13b21a461cb92291c9cd2ae26b",
            "placeholder": "​",
            "style": "IPY_MODEL_5fc79d8f5f2d423b816f61023a5fdc02",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.65kB/s]"
          }
        },
        "9815ba2b6f71456aa54dea35156d0499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e99fc049cd04717a3d07cdd86617709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a7987542eb24e2fbebef9222ed91bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c051adc33fbb46508ef3384243e0e7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0bd7ef23cd4af297acb371f2fad71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83e8dd13b21a461cb92291c9cd2ae26b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc79d8f5f2d423b816f61023a5fdc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c90140b5e5d4bc2842bc18edcd930bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f942f90634e4e36822d445ab8f14f14",
              "IPY_MODEL_af9c7fc9a9f744299e92367a0071c535",
              "IPY_MODEL_6cc1b88d77ef42208ee5496caf07fdf6"
            ],
            "layout": "IPY_MODEL_a3ef89fb98024446a996434cba468850"
          }
        },
        "3f942f90634e4e36822d445ab8f14f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5059e37e036479384a6f3d2aeb001c9",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d3fec8e11f4d7faae2ff9075b6b8a3",
            "value": "config.json: 100%"
          }
        },
        "af9c7fc9a9f744299e92367a0071c535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bbfdbcafb7e4460849a67f811313362",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17730a0210b34d479cf89a7e26583d8f",
            "value": 571
          }
        },
        "6cc1b88d77ef42208ee5496caf07fdf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4ce0bce2774f198253cb5297c864a4",
            "placeholder": "​",
            "style": "IPY_MODEL_d2d97f78081149308a14a9823c439faa",
            "value": " 571/571 [00:00&lt;00:00, 23.9kB/s]"
          }
        },
        "a3ef89fb98024446a996434cba468850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5059e37e036479384a6f3d2aeb001c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d3fec8e11f4d7faae2ff9075b6b8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bbfdbcafb7e4460849a67f811313362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17730a0210b34d479cf89a7e26583d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d4ce0bce2774f198253cb5297c864a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d97f78081149308a14a9823c439faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5efcb7ec4d5941728564946c3bb906d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b848a41a84e47648d1a5b2eb66a2989",
              "IPY_MODEL_3b5e5ef62d4c42f89ff76f64442b74ac",
              "IPY_MODEL_38cdd751528b42efb0ef120cd15455a3"
            ],
            "layout": "IPY_MODEL_e20e86e628234a34b4d4db8fb86f9924"
          }
        },
        "5b848a41a84e47648d1a5b2eb66a2989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda51a0ac7864410a3004b81a04f101c",
            "placeholder": "​",
            "style": "IPY_MODEL_539bcf849ef9400fa473cfa60bb1754d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "3b5e5ef62d4c42f89ff76f64442b74ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d04cc9e8dd9440fa9180849a8dabefd0",
            "max": 438011953,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_332fac6a24f044309ac8b7ecab2bf061",
            "value": 438011953
          }
        },
        "38cdd751528b42efb0ef120cd15455a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_032c467d9d1641f1b7e263cdfd242965",
            "placeholder": "​",
            "style": "IPY_MODEL_74c956e1883d48028cb5c095255b4309",
            "value": " 438M/438M [00:04&lt;00:00, 137MB/s]"
          }
        },
        "e20e86e628234a34b4d4db8fb86f9924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda51a0ac7864410a3004b81a04f101c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539bcf849ef9400fa473cfa60bb1754d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d04cc9e8dd9440fa9180849a8dabefd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332fac6a24f044309ac8b7ecab2bf061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "032c467d9d1641f1b7e263cdfd242965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c956e1883d48028cb5c095255b4309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa26813a662a4a33bd0f1f97ad10bce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d355cf43582142b4832147cd2f97a0fe",
              "IPY_MODEL_acca279e24ea4573b6bddb547e67ca8f",
              "IPY_MODEL_22bf0f04042c4d1794dc543d1cf6bdb9"
            ],
            "layout": "IPY_MODEL_549a948008464aa1afdca7ac890bb672"
          }
        },
        "d355cf43582142b4832147cd2f97a0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09747f345f447d2b8caa67bbff5b621",
            "placeholder": "​",
            "style": "IPY_MODEL_d4037678d47f4cfaaaae0827ffee592e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "acca279e24ea4573b6bddb547e67ca8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7b4ecffc8334f8b9416631a7de8b609",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afb42a97e477411cb891fe3c866eef68",
            "value": 363
          }
        },
        "22bf0f04042c4d1794dc543d1cf6bdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6129429b534764906aacf812ca0d01",
            "placeholder": "​",
            "style": "IPY_MODEL_dad94799475e48fa804797e5a609ad9d",
            "value": " 363/363 [00:00&lt;00:00, 23.5kB/s]"
          }
        },
        "549a948008464aa1afdca7ac890bb672": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09747f345f447d2b8caa67bbff5b621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4037678d47f4cfaaaae0827ffee592e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7b4ecffc8334f8b9416631a7de8b609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afb42a97e477411cb891fe3c866eef68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6129429b534764906aacf812ca0d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad94799475e48fa804797e5a609ad9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdcb2e50e2954179a56710297f8c1119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2580b501dcb944c5a9bcd79cda686b8d",
              "IPY_MODEL_1402cf0d59964a4098f7bb01ef453f03",
              "IPY_MODEL_e4561e58b3914540a10ce7114795655e"
            ],
            "layout": "IPY_MODEL_25a467bb6df64c589dbce36abb925e09"
          }
        },
        "2580b501dcb944c5a9bcd79cda686b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b57b9c2f8a47a9ac0a19b4da8a1915",
            "placeholder": "​",
            "style": "IPY_MODEL_7878a7cb58874314b9fed5ddd04108b2",
            "value": "vocab.txt: 100%"
          }
        },
        "1402cf0d59964a4098f7bb01ef453f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cb0a57b7e04705b76ad6135482005a",
            "max": 231536,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9981379aca0e4772b87120da5a307390",
            "value": 231536
          }
        },
        "e4561e58b3914540a10ce7114795655e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06089cba177444678b9014c613ca6171",
            "placeholder": "​",
            "style": "IPY_MODEL_ca2c78ff92594d0eaaef00ae9f8f2a47",
            "value": " 232k/232k [00:00&lt;00:00, 4.20MB/s]"
          }
        },
        "25a467bb6df64c589dbce36abb925e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b57b9c2f8a47a9ac0a19b4da8a1915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7878a7cb58874314b9fed5ddd04108b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25cb0a57b7e04705b76ad6135482005a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9981379aca0e4772b87120da5a307390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06089cba177444678b9014c613ca6171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca2c78ff92594d0eaaef00ae9f8f2a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1154f972d6664eba99b1ea73c926c85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caac90c8a099434fbd7c6bccd18e4263",
              "IPY_MODEL_21ee94c063e348eca7078ecc303ce99d",
              "IPY_MODEL_6e20ca45f01446cd8277f31cf43851ae"
            ],
            "layout": "IPY_MODEL_921f1bc43812425dacdfb262ac0d12f3"
          }
        },
        "caac90c8a099434fbd7c6bccd18e4263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79199d7b7274ace9ff8233922979879",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac7e32cc4e14e22a692180fcc35b624",
            "value": "tokenizer.json: 100%"
          }
        },
        "21ee94c063e348eca7078ecc303ce99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4da545ae8014645a54607530549dd69",
            "max": 466021,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eab02a9a1dc4159b0e37bc051c5623c",
            "value": 466021
          }
        },
        "6e20ca45f01446cd8277f31cf43851ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c4900b8cb014b20a8f5678b4ed9441f",
            "placeholder": "​",
            "style": "IPY_MODEL_f0d8e820d9fd48b49ae4f586fe02a650",
            "value": " 466k/466k [00:00&lt;00:00, 9.33MB/s]"
          }
        },
        "921f1bc43812425dacdfb262ac0d12f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79199d7b7274ace9ff8233922979879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac7e32cc4e14e22a692180fcc35b624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4da545ae8014645a54607530549dd69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eab02a9a1dc4159b0e37bc051c5623c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c4900b8cb014b20a8f5678b4ed9441f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0d8e820d9fd48b49ae4f586fe02a650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a42395df5019409f8c32d7b0a54294e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7661e755b40455fa80c8832865f7932",
              "IPY_MODEL_bc00fff5eb764e8fac0e05772b05ff59",
              "IPY_MODEL_0c92e0a349af44a18587c5ab9154461c"
            ],
            "layout": "IPY_MODEL_ea8beb99424d43229674c30d3f80ca84"
          }
        },
        "f7661e755b40455fa80c8832865f7932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b3e401b5db347b0a074ee61d7109c06",
            "placeholder": "​",
            "style": "IPY_MODEL_6c81bb36eb984433bfa7efc889e79761",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "bc00fff5eb764e8fac0e05772b05ff59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1de512c68a64760b7545a954d4b0888",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df640a16bbe46ecad999c4d27300cf0",
            "value": 239
          }
        },
        "0c92e0a349af44a18587c5ab9154461c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e0ebeb04b145fd96d594f94dce303b",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4471f3ab9242e98c00dbade4327857",
            "value": " 239/239 [00:00&lt;00:00, 17.9kB/s]"
          }
        },
        "ea8beb99424d43229674c30d3f80ca84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3e401b5db347b0a074ee61d7109c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c81bb36eb984433bfa7efc889e79761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1de512c68a64760b7545a954d4b0888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df640a16bbe46ecad999c4d27300cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38e0ebeb04b145fd96d594f94dce303b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4471f3ab9242e98c00dbade4327857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fff1cd270ce24b7f933f76b030fe4c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_653482970e214f23aa66b72caade4027",
              "IPY_MODEL_9451c8ec3f844a71813b4848876fb78e",
              "IPY_MODEL_97cd03aa548a499f9bc790656e977ad9"
            ],
            "layout": "IPY_MODEL_27e4c247d2194e49b0c30c36c8a3c277"
          }
        },
        "653482970e214f23aa66b72caade4027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23a9b058aed4bac8f0d540516dba585",
            "placeholder": "​",
            "style": "IPY_MODEL_9e82e62818a04c2dae0e82a5d6f797a4",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "9451c8ec3f844a71813b4848876fb78e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7368af9e5ec04a6c9a3fbdc9bbf2d6e1",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a4f66807baa4929875eef49f45c95de",
            "value": 190
          }
        },
        "97cd03aa548a499f9bc790656e977ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2d94b090e547deab6d8cbf42788b26",
            "placeholder": "​",
            "style": "IPY_MODEL_153b4585aa574ed18c453e031c187b54",
            "value": " 190/190 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "27e4c247d2194e49b0c30c36c8a3c277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f23a9b058aed4bac8f0d540516dba585": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e82e62818a04c2dae0e82a5d6f797a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7368af9e5ec04a6c9a3fbdc9bbf2d6e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a4f66807baa4929875eef49f45c95de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be2d94b090e547deab6d8cbf42788b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "153b4585aa574ed18c453e031c187b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_BJIrwoPZu8",
        "outputId": "bb78a0d0-89ce-435b-8ed3-1c1f9122ed9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformers:\n",
        "\n",
        "Purpose:\n",
        "Enables you to build, train, and use various Natural Language Processing (NLP) models, including transformers like BERT, GPT-2, and T5.\n",
        "Offers pre-trained models for a wide range of tasks, such as text classification, question answering, sentiment analysis, and summarization.\n",
        "\n",
        "Key Features:\n",
        "Modular architecture for creating custom NLP models.\n",
        "Support for multiple machine learning frameworks (PyTorch, TensorFlow).\n",
        "Extensive pre-trained model library covering diverse languages and tasks.\n",
        "\n",
        "Use Cases:\n",
        "Chatbots and virtual assistants.\n",
        "Machine translation.\n",
        "Text summarization and generation.\n",
        "Text classification and sentiment analysis.\n",
        "Document processing and information extraction.\n",
        "\n",
        "einops:\n",
        "\n",
        "Purpose:\n",
        "Simplifies and improves tensor manipulation in high-dimensional data (especially PyTorch tensors).\n",
        "Offers expressive syntax for Einstein summation-like operations and advanced indexing.\n",
        "Key Features:\n",
        "Reduces boilerplate code for common tensor operations.\n",
        "Enhances clarity and readability of tensor manipulations.\n",
        "Works seamlessly with existing PyTorch code and functionality.\n",
        "Use Cases:\n",
        "Neural network architectures that heavily rely on tensor reshaping and indexing.\n",
        "Scientific computing and numerical mathematics involving tensors.\n",
        "Deep learning research and experimentation with custom tensor operations.\n",
        "\n",
        "accelerate:\n",
        "\n",
        "Purpose:\n",
        "Accelerates deep learning training on GPUs (and potentially other hardware) through mixed-precision training and gradient accumulation.\n",
        "Provides a distributed training framework for multi-GPU and multi-node setups.\n",
        "Key Features:\n",
        "Automatic mixed-precision training for reduced memory usage and faster training.\n",
        "Gradient accumulation to improve training stability and converge to better optima.\n",
        "Distributed training support for scaling computations across multiple devices.\n",
        "Use Cases:\n",
        "Training large and complex deep learning models on a single GPU or multiple GPUs.\n",
        "Optimizing training speed and resource utilization for computationally intensive models.\n",
        "Large-scale deep learning projects that require distributed training across machines.\n",
        "\n",
        "langchain:\n",
        "\n",
        "Purpose:\n",
        "Facilitates building modular NLP pipelines by chaining together transformers and other NLP components.\n",
        "Streamlines the process of composing complex NLP workflows involving multiple steps.\n",
        "Key Features:\n",
        "Modular design for easily composing NLP tasks into pipelines.\n",
        "High-level abstractions for task-specific components.\n",
        "Integration with transformers and other NLP libraries.\n",
        "Use Cases:\n",
        "Developing multi-stage NLP pipelines for tasks like information extraction or question answering.\n",
        "Designing and experimenting with custom NLP workflows.\n",
        "Simplifying complex NLP projects by separating concerns and promoting code reuse.\n",
        "\n",
        "bitsandbytes:\n",
        "\n",
        "Purpose:\n",
        "Provides specialized data structures and utilities for numerical computing, signal processing, and audio/image manipulation.\n",
        "Offers efficient implementations for working with fixed-point numbers, bitwise operations, and low-level data representations.\n",
        "Key Features:\n",
        "Optimized data types for low-level numerical computations.\n",
        "Bitwise operation support for various tasks like encoding/decoding data or implementing custom algorithms.\n",
        "Tools for audio and image processing using bit-level manipulations.\n",
        "Use Cases:\n",
        "Signal processing and audio/image algorithms that benefit from bit-level control.\n",
        "Implementations of resource-efficient neural networks (e.g., for embedded devices).\n",
        "Low-level numerical computations requiring fine-grained control over data representations."
      ],
      "metadata": {
        "id": "9s_FZ6T_Q2cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyI_tzeHPg-N",
        "outputId": "be1e156f-944a-4d1e-9674-0b37e6364bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m826.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Embedding\n",
        "!pip install install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXe3t8rNP54r",
        "outputId": "0f35aec5-46d4-481d-f9c4-46685df4c2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: install in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk4YtKmCRLzZ",
        "outputId": "2b21ba25-09ae-4738-ebf7-32a9327dae00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.9.40-py3-none-any.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.6.3)\n",
            "Collecting deprecated>=1.2.9.3 (from llama_index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama_index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2023.6.0)\n",
            "Collecting httpx (from llama_index)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.23.5)\n",
            "Collecting openai>=1.1.0 (from llama_index)\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama_index)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (4.5.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama_index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama_index) (1.3.0)\n",
            "Collecting typing-extensions>=4.5.0 (from llama_index)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->llama_index)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama_index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama_index) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama_index) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama_index) (1.16.0)\n",
            "Installing collected packages: dirtyjson, typing-extensions, h11, deprecated, tiktoken, httpcore, httpx, openai, llama_index\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama_index-0.9.40 openai-1.10.0 tiktoken-0.5.2 typing-extensions-4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. llama_index:\n",
        "\n",
        "VectorStoreIndex: This class helps you create and manage vector-based indices for text data. It stores text documents as dense vectors representing their semantic content, enabling fast and efficient retrieval and similarity search.\n",
        "SimpleDirectoryReader: This class reads text documents from a specified directory on your file system, preparing them for indexing.\n",
        "ServiceContext: This class manages configurations and settings for various services involved in the indexing process, such as language models and embedding models.\n",
        "2. llama_index.llms:\n",
        "\n",
        "HuggingFaceLLM: This class provides an interface to interact with language models hosted on Hugging Face. It allows you to send text prompts and receive responses from these models.\n",
        "3. llama_index.prompts.prompts:\n",
        "\n",
        "SimpleInputPrompt: This class represents a basic text prompt used to query a language model. It holds the text string to be sent as input to the model.\n",
        "Typical Workflow with These Libraries:\n",
        "\n",
        "Set up Service Context:\n",
        "Configure necessary settings like the language model to use and embedding model for vectorization.\n",
        "Load Documents:\n",
        "Use a reader like SimpleDirectoryReader to load text documents from a directory.\n",
        "Create Index:\n",
        "Build a VectorStoreIndex by providing the loaded documents and relevant settings.\n",
        "Query the Index:\n",
        "Use query methods to find similar documents or retrieve relevant information based on text prompts.\n",
        "Employ language models like HuggingFaceLLM to generate responses or perform other text-based tasks.\n",
        "Key Considerations:\n",
        "\n",
        "llama_index primarily focuses on text indexing and retrieval.\n",
        "HuggingFaceLLM offers access to a wide range of language models on Hugging Face's platform.\n",
        "For specific functionalities or tasks, you might need to import additional components from these libraries or leverage other NLP tools."
      ],
      "metadata": {
        "id": "xDX4WfbhSXmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "from llama_index.prompts.prompts import SimpleInputPrompt"
      ],
      "metadata": {
        "id": "Bw0OueINRQam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "from os import path\n",
        "\n",
        "if path.exists('/content/data') == False:\n",
        "  os.mkdir('/content/data')\n",
        "\n",
        "os.chdir('/content/data')\n",
        "!pwd\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlTEbOMuT5at",
        "outputId": "d7d71b19-3f21-4153-9c79-d583d04e3f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=SimpleDirectoryReader(\"/content/data\").load_data()\n",
        "documents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvBLm508RlKo",
        "outputId": "c4185243-bfee-4ad1-b42a-7a42b5b9f375"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id_='3b1077bf-92fa-4f00-a9bd-6b376d7e4424', embedding=None, metadata={'page_label': '1', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Preprint submitted to Medical Image Analysis (2023)\\nA residual dense vision transformer for medical image super-resolution with\\nsegmentation-based perceptual loss ﬁne-tuning\\nJin Zhua,∗, Yang Guangb,c,1,∗, Pietro Li ´oa,1\\naDepartment of Computer Science and Technology, University of Cambridge, Cambridge CB3 0FD, UK\\nbNational Heart and Lung Institute, Imperial College London, London SW3 6LY, UK\\ncCardiovascular Research Centre, Royal Brompton Hospital, London SW3 6LR, UK\\nA R T I C L E I N F O\\nArticle history :\\nReceived 06 March 2023\\nReceived in ﬁnal form None\\nAccepted None\\nAvailable online None\\nCommunicated by None\\n2020 MSC: 68U10, 2020 MSC: 68T07,\\n2020 MSC: 92B20, 2020 MSC: 62P10\\nKeywords: Vision transformers, Su-\\nper-resolution, Medical image analy-\\nsis, Image processing, Perceptual loss,\\nResidual learning, Enhanced image qual-\\nity assessment, Medical image segmen-\\ntationA B S T R A C T\\nSuper-resolution plays an essential role in medical imaging because it provides an al-\\nternative way to achieve high spatial resolutions and image quality with no extra ac-\\nquisition costs. In the past few decades, the rapid development of deep neural net-\\nworks has promoted super-resolution performance with novel network architectures,\\nloss functions and evaluation metrics. Speciﬁcally, vision transformers dominate a\\nbroad range of computer vision tasks, but challenges still exist when applying them\\nto low-level medical image processing tasks. This paper proposes an e ﬃcient vision\\ntransformer with residual dense connections and local feature fusion to achieve e ﬃcient\\nsingle-image super-resolution (SISR) of medical modalities. Moreover, we implement\\na general-purpose perceptual loss with manual control for image quality improvements\\nof desired aspects by incorporating prior knowledge of medical image segmentation.\\nCompared with state-of-the-art methods on four public medical image datasets, the pro-\\nposed method achieves the best PSNR scores of 6 modalities among seven modalities.\\nIt leads to an average improvement of +0.09 dB PSNR with only 38% parameters of\\nSwinIR. On the other hand, the segmentation-based perceptual loss increases +0.14 dB\\nPSNR on average for SOTA methods, including CNNs and vision transformers. Ad-\\nditionally, we conduct comprehensive ablation studies to discuss potential factors for\\nthe superior performance of vision transformers over CNNs and the impacts of network\\nand loss function components. The code will be released on GitHub with the paper\\npublished.\\n©2023 All rights reserved.\\n1. Introduction\\nMedical images are crucial in the current clinical process, including early detection, staging, guiding intervention procedures and\\nsurgeries, radiation therapy, and monitoring disease recurrence [Brody (2013)]. For example, computed tomography (CT) and\\nmagnetic resonance (MR) scans are widely used in the diagnosis and study of Alzheimer’s disease [Mirzaei et al. (2016)], stroke\\n[Mirzaei and Adeli (2016)], autism [Leming et al. (2020)], Parkinson’s disease [Castillo-Barnes et al. (2020)] and COVID-19\\n[Ozsahin et al. (2020)]. Although people have witnessed the importance of in-vivo radiology images, their spatial resolution is\\nsubject to the scan time, body motion, dose limit and hardware conﬁgurations. Thus, super-resolution methods are introduced as\\nalternative post-processing to achieve higher resolution and better image quality without extra acquisition costs [Li et al. (2021b)].\\nTechnically, image super-resolution is a process to recover an image of high-resolution (HR) from low-resolution (LR) versions.\\nDepending on the number of input and output images, we brieﬂy divide the methods into two groups: single-image super-resolution\\n∗Corresponding author: zhujin1121@gmail.com; g.yang@imperial.ac.uk\\n1Co-last senior authors contributed equally.\\nPreprint submitted to Medical Image Analysis March 6, 2023 arXiv:2302.11184v2  [eess.IV]  3 Mar 2023', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='b535cf55-2de5-474e-bb8a-64cdc78c622b', embedding=None, metadata={'page_label': '2', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='2 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\n(SISR) and multi-image super-resolution. With the rapid development of deep learning algorithms, SISR methods with neural net-\\nworks achieve superior performance on natural images than the previous interpolation-based, reconstruction-based, and learning-\\nbased methods [Yang et al. (2019); Wang et al. (2020); Lepcha et al. (2022)]. However, introducing deep neural networks to medical\\nimage super-resolution tasks is still an open problem. In the clinic, super-resolved images always proceed to medical image analy-\\nsis tasks, and the datasets are relatively small [Shen et al. (2017); Litjens et al. (2017); Chan et al. (2020)]. Thus, super-resolution\\nmethods for medical images require novel mechanisms and modiﬁcations on training datasets, loss functions, evaluation metrics\\nand network architecture design to preserve sensitive information and to enhance the structures of interest for radiologists and\\nphysicians [Li et al. (2021b)].\\nRecently, convolutional neural networks (CNNs) and generative adversarial networks (GANs) have successfully applied to medical\\nimage super-resolution tasks [Li et al. (2021b)]. However, it is still an open problem to involve vision transformers (ViTs), which\\nachieve state-of-the-art performance on a wide range of natural image restoration tasks [Han et al. (2020)] and medical image anal-\\nysis tasks [Henry et al. (2022); He et al. (2022a)]. Exploring and discussing the robustness, capacity, e ﬃciency and limitation of\\nvision transformers on medical image SR tasks is necessary. On the other hand, acknowledged tricks of CNN architecture design,\\nsuch as localisation operation, residual connections and feature fusion, are worth introducing to CNN-ViT hybrid models for poten-\\ntial performance improvement. For example, inspired by the shared weights and localisation operations of CNNs, a shifted window\\nvision transformer (Swin Transformer [Liu et al. (2021)]) is proposed for high-level image processing tasks. The novel Swin layers\\nare then applied in natural image restoration [Liang et al. (2021); Fan et al. (2022)] and segmentation [He et al. (2022b); Cao et al.\\n(2021)].\\nAdditionally, prior knowledge of related medical image tasks, such as segmentation, can beneﬁt the upstream super-resolution\\ntask. On the one hand, the challenges of performing image quality assessment (IQA) on enhanced images [Chandler (2013)] and on\\nmedical images [Chow and Paramesran (2016)] still exist. Generally, IQA of generated and super-resolved natural images mainly\\nincludes reconstruction accuracy and human perception. Since current SISR methods are getting close to the limitation of signal\\nﬁdelity metrics [Wang and Bovik (2009)], perceptual quality assessment methods [Zhai and Min (2020)] have become more and\\nmore critical. In contrast, various artefacts in medical images, mainly caused by the hardware of imaging systems and the body mo-\\ntion of individuals, are never seen in natural images. Peak signal-to-noise ratio (PSNR) and structure similarity (SSIM [Zhou Wang\\net al. (2004)]) are prevalent in almost every medical image SR work. However, directly and only using the IQA methods designed\\nfor natural images may not be reliable in medical image SR tasks. In a supplemental manner, researchers evaluate the quality of SR\\nimages with the performance of downstream medical image analysis tasks such as segmentation [Xia et al. (2021)]. Although the\\nquality measurement of medical images does not equal diagnostic accuracy [Cavaro-Menard et al. (2010)], radiologists and medical\\nconsultants always prefer high-quality images for accurate diagnosis. In addition to the measurement of machine perception, the\\nprior knowledge of pre-trained segmentation models can also beneﬁt the training of medical image super-resolution models, similar\\nto the existing perceptual losses [Johnson et al. (2016); Bell et al. (2015)].\\nThus, we explore the possibility of extending successful architectures in CNNs to vision transformers to improve the single-image\\nsuper-resolution performance of medical images e ﬃciently and robustly. We propose a Residual Dense Swin Transformer (RDST)\\nas a novel backbone for SR tasks by introducing residual dense connections [Huang et al. (2017); Tong et al. (2017)] and local', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='be1c27e6-a3a2-46a0-ae28-74898de5c1b5', embedding=None, metadata={'page_label': '3', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 3\\nfeature fusion [Zhang et al. (2018b); Wang et al. (2018)] to SOTA vision transformers. Meanwhile, we take segmentation as a\\ntypical medical image analysis task in the clinic and connect it with the upstream super-resolution task for model training and\\nresult evaluation. We present a perceptual loss based on the prior knowledge of the pre-trained segmentation U-Net [Ronneberger\\net al. (2015)] and extend its variants to a wide range of SOTA SISR models, including CNNs and ViTs. In this work, we focus\\non supervised super-resolution with a single magniﬁcation scale (i.e. ×4). At the same time, the proposed method has potential\\napplicability to semi- /un-supervised SR tasks with multi or arbitrary magniﬁcation scales. For a comprehensive comparison with\\nSOTA SISR methods, we run experiments on four big and small public medical image datasets, including brain MR images, cardiac\\nMR images and CT scans of COVID patients. Ablation studies are also designed to discuss the impacts of critical characteristics of\\nthe proposed model architecture, perceptual loss and training tricks.\\nThe paper is organised as follows: in Section 2, we brieﬂy summarise related works of single image super-resolution; in Sec-\\ntion 3, we introduce the proposed residual dense vision transformer and the segmentation task based perceptual loss; in Section\\n4, we describe the experiment settings; in Section 5, we illustrate the qualitative and quantitative results and discuss the essential\\ncharacteristics of the proposed method in contrast with SOTA SISR methods; and in Section 6, we provide concluding remarks of\\nthis work.\\n2. Related work\\nThis section provides a comprehensive review of advanced super-resolution networks with medical image applications.\\n2.1. Super-resolution networks\\nImplementation of super-resolution networks includes CNNs [Dong et al. (2015); Lim et al. (2017); Zhang et al. (2018a)], GANs\\n[Ledig et al. (2017); Wang et al. (2018)], vision transformers [Zamir et al. (2022); Liang et al. (2021); Lu et al. (2022)], di ﬀusion\\nmodels [Chen et al. (2021); Li et al. (2022b); Ho et al. (2022)] and hybrid methods [Gao et al. (2022)]. These frameworks involve\\na wide range of deep learning techniques, such as recursive learning [Tai et al. (2017b); Kim et al. (2015); Tai et al. (2017a);\\nGao et al. (2022)], local and global residual learning [Zhang et al. (2018b); Li et al. (2018); Hui et al. (2018); Kim et al. (2016)],\\nmulti-path learning [Lim et al. (2017); Han et al. (2018); Ren et al. (2017); Mehri et al. (2021)], attention mechanisms [Zhang et al.\\n(2018a); Dai et al. (2019); Niu et al. (2020)] and U-Net architectures [Park et al. (2018); Liu et al. (2018); Qiu et al. (2022)]. For a\\ncomprehensive review of SISR networks, we refer to the three citations [Wang et al. (2020); Yang et al. (2019); Lepcha et al. (2022)].\\nEarly SISR networks such as SRCNN [Dong et al. (2015)], VDSR [Kim et al. (2016)], MemNetTai et al. (2017b)] and DRCN\\n[Kim et al. (2015)] follow the pre-upsampling architecture design, which ﬁrst upsamples the LR image to the desired size and\\nreﬁnes the magniﬁed results with limited convolution layers. Then, post-upsampling frameworks are proposed in ESPCN [Shi et al.\\n(2016)] and FSRCNN [Dong et al. (2016)], which apply feature learning in low-resolution space and achieve feature maps magni-\\nﬁcation subsequently. Moreover, residual connections are widely used for advanced representation capability in deep SR networks\\nwithout gradient vanishing. SRResNet [Ledig et al. (2017)] ﬁrst introduces the residual block of ResNet [He et al. (2015a)] with\\nGANs for photo-realistic image generation. Then, EDSR [Lim et al. (2017)] and SRDenseNet [Tong et al. (2017)] further improve\\nthe block architectures by removing the unnecessary batch-normalisation layer [Io ﬀe and Szegedy (2015)] and introducing dense\\nconnections. Moreover, RDN [Zhang et al. (2018b)] and ESRGAN [Wang et al. (2018)] implement local feature fusion to reduce', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='f720a495-fa3b-436b-b54c-a6777149a18f', embedding=None, metadata={'page_label': '4', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='4 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nthe computation cost of dense blocks and encourage more stable information and gradient ﬂows.\\nAttention mechanism adaptively realises deep neural networks to most informative regions of the input, leading to a more e ﬃ-\\ncient and e ﬀective understanding of complex scenes in computer vision tasks [Guo et al. (2022a)], such as super-resolution [Zhu\\net al. (2021a)]. RCAN [Zhang et al. (2018a)] ﬁrst introduce the channel attention mechanism into residual SR networks, leading\\nto ﬂexible processing of low- /high-frequency information with channel-wise interdependence learning on features maps. Addi-\\ntionally, advanced CNN-based methods apply multi-scale Laplacian pyramid attention [Anwar and Barnes (2020)] second-order\\nchannel attention [Dai et al. (2019)] and spatial attention [Choi and Kim (2017); Liu et al. (2020)]. HAN [Niu et al. (2020)] further\\nimplements a holistic attention network with the hybrid channel-spatial attention and the layer attention modules.\\nTransformers are ﬁrst applied for natural language processing [Vaswani et al. (2017)] and then introduced to vision tasks [Han\\net al. (2020); Henry et al. (2022)] by embedding image and feature maps to tokens. For low-level image restoration tasks, IPT\\n[Chen et al. (2021)] involves CNN-based shallow feature embedding before self-attention layers and transfer learning of pre-trained\\nmodel on ImageNet [Deng et al. (2009)]. SwinIR [Liang et al. (2021)] proposes an e ﬃcient transformer backbone based on the\\nshifted-window attention [Liu et al. (2021)] and achieves SOTA performance on a broad range of natural image restoration tasks.\\nSimilarly, Uformer [Wang et al. (2022)] implements a U-Net framework with locally-enhanced window transformer blocks and a\\nnovel multi-scale restoration modulator for multi-task learning on image restoration. Both SwinIR and Uformer transformers suc-\\ncessfully avoid the expensive computational cost of global self-attention on high-resolution feature maps and the limitation of trans-\\nformers in capturing local dependencies. Meanwhile, the multi-deconv transposed attention and gated-dconv feed-forward network\\nare proposed in Restormer [Zamir et al. (2022)] to aggregate local and non-local pixel interactions and perform controlled feature\\ntransformation. Additionally, hybrid CNN and transformer methods are proposed for e ﬃcient and lightweight super-resolution [Lu\\net al. (2022); Zou et al. (2022); Fang et al. (2022)].\\n2.2. SR on medical images\\nBefore the explosion of deep neural networks, early applications of medical image super-resolution mainly relied on interpolation,\\nreconstruction and example-learning methods [Isaac and Kulkarni (2015)]. Although these methods involve multi frames [Peled\\nand Yeshurun (2001); Greenspan et al. (2002); Shilling et al. (2008)] and reference slices [Rousseau (2008); Manj ´on et al. (2010)]\\nfor HR image reconstruction, they achieve poor performance due to the limited representational capacity and lack of additional\\ninformation of the training data.\\nResearchers extend SRCNN [Dong et al. (2015)] with proper modiﬁcations to brain MR super-resolution [Pham et al. (2017);\\nMcDonagh et al. (2017); Du et al. (2020)] and cardiac MR reconstruction with multi-input [Oktay et al. (2016)]. [Shi et al. (2018)\\npresents a pre-upsampling SR framework modiﬁed residual blocks of EDSR [Lim et al. (2017)] for 2D brain MR slices. [Chen\\net al. (2018b) and [Li et al. (2021a)] applies 3D convolution in one dense connected block [Tong et al. (2017)] for 3D brain MR\\nsuper-resolution and liver tumour CT images. In [Zhao et al. (2019)], researchers propose a channel splitting network with global\\nfeature fusion [Zhang et al. (2018b) and merge-and-run mapping [Zhao et al. (2016)], leading to a representational redundancy de-\\ncline and hierarchical features integration. U-Net architectures are also widely used in medical image super-resolution tasks [Park\\net al. (2018); Qiu et al. (2022, 2021)], especially for multi-task learning with segmentation [Oktay et al. (2017); Bhandary et al.\\n(2022)].', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='237312fe-f611-4a00-a228-afccab0bd985', embedding=None, metadata={'page_label': '5', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 5\\nAdversarial learning and the perceptual loss [Johnson et al. (2016)] are also widespread in single slice super-resolution due to\\nthe expensive computation cost of 3D operations [Chen et al. (2018a); S ´anchez and Vilaplana (2018)]. [Gu et al. (2020)] imple-\\nments a conditional GAN framework with a modiﬁed RCAN [Zhang et al. (2018a)] for 2D super-resolution on CT and MR images.\\nFA-GAN [Jiang et al. (2021)] proposes a fused attentive GAN with CNN-based channel and non-local attentions for 2D MR super-\\nresolution. FP-GANs [You et al. (2022)] conducts SR in a divide-and-conquer manner with multiple ESRGAN [Wang et al. (2018)]\\nin the wavelet domain. CycleGAN [Zhu et al. (2020)] also beneﬁts medical image super-resolution [You et al. (2019)], such as\\nwith lesion-focused [de Farias et al. (2021)] and semi-supervised training [Jiang et al. (2020)]. Meanwhile, Wasserstein distances\\n[Arjovsky et al. (2017); Gulrajani et al. (2017)] are also widely used [Lyu et al. (2018); Shahidi (2021); Yang et al. (2018); Lyu\\net al. (2020); Zhu et al. (2018, 2019, 2021b)].\\nVision transformers boost the performance of medical image processing tasks such as reconstruction [Guo et al. (2022b); Huang\\net al. (2022), denoising [Jang et al. (2022)] and segmentation [Tang et al. (2022b)]. [Puttaguntaa et al. (2022)] present a SwinIR\\napplication on medical images, including chest x-ray, skin lesions and funds images. Meanwhile, [Li et al. (2022a)] apply SwinIR\\nfor multi-contrast MR super-resolution with multi-scale contextual matching and aggregation schemes.\\nBased on a comparison study of state-of-the-art single-image super-resolution methods on four public medical image datasets,\\nweclaim that the main contributions of this work include:\\n•A Residual Dense Swin Transformer (RDST) is proposed by introducing the residual dense connections to vision transform-\\ners. In the×4 SR experiments on four medical image datasets, it achieves the best PSNR scores of 6 modalities among 7\\nmodalities in total. It leads to +0.09 dB PSNR improvement on average than the SOTA SISR method SwinIR with only\\n38% parameters. Additionally, the SR results of RDST achieve the best segmentation accuracy of 8 sub-regions among all\\n15 target regions in the downstream segmentation tasks and increase the dice coe ﬃcient by 0.0029 on average than the SR\\nresults of SwinIR.\\n•The lite version RDST-E further improves the model e ﬃciency with hyper-parameter modiﬁcation. It achieves comparable\\nperformance with the SOTA method SwinIR on both SR image quality ( +0.06 dB PSNR on average of 7 medical image\\nmodalities) and downstream segmentation accuracy (-0.0026 dice coe ﬃcient on average of 15 target regions) but has only\\n20% parameters of SwinIR and is 46% faster than SwinIR on inference.\\n•Two variants of SR perceptual loss are proposed with pre-trained segmentation U-Nets, dramatically improving the SR image\\nquality by transferring prior knowledge of medical images in segmentation tasks to super-resolution tasks. The proposed\\nlosses successfully extend to various SOTA SISR methods, including CNNs and ViTs. Compared with the native L1 loss, the\\nnovel loss variant for SR ﬁdelity (i.e. LE(1)) results in a noticeable improvement of +0.14 dB PSNR on average, while the\\nproposed loss variant for machine perception (i.e. LHRL) leads to an improvement of +0.0023 dice coe ﬃcient on average in\\nthe downstream segmentation task.\\n3. Methods\\nIn this work, we mainly focus on single image super-resolution tasks with certain magniﬁcation scales (e.g. ×4), which can be\\nrepresented as:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='434978e8-8dbf-4800-a580-46aa3a91751f', embedding=None, metadata={'page_label': '6', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='6 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nFig. 1. Framework of the proposed RDST network. (a): the proposed RDST (notation represented with Eq. 2) consists of a convolution layer head for\\nshallow feature extraction, a SubPixel-based UpSampler, NRDSTB modules and a global residual connection. (b): A residual dense Swin transformer\\nblock (notation presented with Eq. 5) is composed of three DSTB modules and a local feature fusion module (LFF), which compress the feature maps from\\n(3×g+d)tod. (c): A Dense STL Block (notation presented with Eq. 4) is composed of two successive swin transformer layers (STLs), a bottleneck layer\\nand a concatenation operator. (d): The two successive shifted-window transformer layers (notation presented in Eq. 3). Each STL consists of two-layer\\nnormalisation layers, one multi-head self-attention layer with regular or shifted windowing conﬁgurations (W-MSA and SW-MSA), one MLP layer and\\nskip connections. The patch embedding and un-embedding operations are ignored for a brief illustration. They convert feature maps from [N×d×H×W]\\nto[Nw×P×d]and vice visa to adjust linear layers and the convolution layers.\\nIsr=Gs(Ilr;θG), (1)\\nwhere sis the magniﬁcation scale, IlrandIsrare a pair of one input image with a low resolution of [ H×W×C] and its super-resolved\\noutput with a high resolution of [ sH×sW×C]. Following the most popular and successful architecture of SISR networks, the\\nproposed residual dense transformer consists of three components: a convolutional layer consisted shallow feature extraction head\\nH, a feature map up-sampler Uand a main body for deep feature extraction (Fig. 1-a). Mathematically, it can be represented as:\\nFlr=H(Ilr),\\nFd=Flr+Ck×k(Rn(Flr)),\\nIsr=Us(Fd), (2)\\nwhere sis the magniﬁcation scale, dis the basic dimension of feature map embedding, Ck×kis a convolutional layer with kernel\\nsizekandRnindicates nsequentially stacked blocks. Similar to SOTA SISR methods, we use one 3 ×3×dconvolutional layer\\nas the head to extract the low-resolution feature maps Flr∈RH×W×dand a Sub-Pixel [Shi et al. (2016)] module as the up-sampler\\nfor super-resolution image generation. Regarding the main body for deep feature extraction, we use a skip connection for global\\nresidual learning and propose a residual dense swin transformer block (RDSTB), which will be introduced in detail in the following\\npart.\\n3.1. Residual dense swin transformer block\\nShifted-windows transformer layer (STL) is used as the most basic unit in the proposed residual dense swin transformer block. To\\nreduce the computation cost in the vision transformer, it splits the input feature maps of size [ H×W] to windows of size [ M×M] ﬁrst\\nand then applies standard multi-head self-attention localised in each window. To connect these local windows, in two successive\\nSTLs (Fig. 1-d), the ﬁrst STL applies regular window partition from top-left, while the second STL shifts the feature maps by\\n(M\\n2,M\\n2) pixels before partition:', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='de77fdfc-aed0-44b4-aaf1-05427034a4b3', embedding=None, metadata={'page_label': '7', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 7\\nˆFi=AW(N(Fi−1))+Fi−1,\\nFi=M(N(ˆFi))+ˆFi,\\nˆFi+1=AS(N(Fi))+Fi,\\nFi+1=M(N(ˆFi+1))+ˆFi+1, (3)\\nwhereAWandASare multi-head self-attention layers with regular and shifted window conﬁgurations, respectively. Nis layer nor-\\nmalisation, andMis a multi-layer perceptron (MLP) consisting of two fully-connected layers with GELU non-linearity [Hendrycks\\nand Gimpel (2016)] in between. Skip connections with pixel-wise addition are applied after each module. The key advantages of\\nSTL are the localisation operation and shared weights, just like convolutional layers. Additionally, with the reshaping operation,\\nthe size of its output feature maps remains the same as the input feature maps (i.e. [ N×d×H×W]). Thus, it behaves like a\\nconvolutional layer, and successful designs in CNN-based SISR models can be easily introduced in STL-based models.\\nFirst, we introduce dense connection [Huang et al. (2017); Tong et al. (2017)] to STLs. As shown in Fig. 1-c, a Dense STL\\nBlock (DSTB) consists of two successive STLs S2and an MLP-based bottleneck module Nd→g. Before concatenating to the input\\nfeature maps Fi−1\\nd, the new feature maps are compressed from [ N×H×W×d] to [ N×H×W×g] to reduce the computation cost\\nfurther. Thus, the output of the i-th DSTB is computed as:\\nFi\\nd+g=cat[Fi−1\\nd,Bd→g(S2(Fi−1d))]. (4)\\nThen, the residual dense swin transformer block (RDSTB, Fig. 1-b) is proposed by applying local feature fusion (LLF) [Zhang et al.\\n(2018b)] after stacking several DSTBs. One RDSTB consists of three successive DSTBs and a 3 ×3 convolutional layer for local\\nfeature fusion. As reported in SRDenseNet [Tong et al. (2017)] and [RDN Zhang et al. (2018b)], combining dense connections and\\nLLF can preserve the feed-forward nature and extract local features without high computational costs and training problems. The\\nconvolution-based LLF controls the output information by reducing the number of feature maps from (3 ×g+d) tod. As a result,\\nthe output feature maps Fiof the i-th RDSTB block remains the same shape [ N×d×H×W] as its input feature maps Fi−1:\\nFi\\nd=Fi−1\\nd+B3×g+d→d(D3(Fi−1\\nd)), (5)\\nwhereD3is a group of three successive DSTBs and Bis the bottleneck module for local feature fusion.\\n3.2. Segmentation U-Net based perceptual loss\\nThe proposed method RDST is trained in two stages: basic training with L1loss and a ﬁne-tuning stage with perceptual loss. In\\nthe ﬁrst stage, the parameters are optimised by minimising the native pixel-wise L1 distance between the output SR images and HR\\nground truth images:\\nL1(G(Ilr),Ihr)=1\\nsH×sW×C∥G(Ilr)−Ihr∥1, (6)\\nwhere Gis a RDST model, sis the magniﬁcation scale, Ilris the input low resolution image with shape [ H×W×C] and Ihris the\\ncorresponding ground truth high resolution image.\\nIn the second stage, a U-Net [Ronneberger et al. (2015)] based segmentation loss is proposed to ﬁne-tune the parameters of the', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='95bb0b84-cc59-4054-89ce-9b4da4ded227', embedding=None, metadata={'page_label': '8', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='8 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nFig. 2. The segmentation U-Net [Ronneberger et al. (2015)] is used in this work for two purposes: for perceptual losses and for segmentation-based SR\\nevaluation. It consists of 5 levels of ResNet-based encoders and decoders, which are paired with skip connections. E1 to E5 indicate the output feature\\nmaps of each encoder block correspondingly, while D denotes the output of the last decoder.\\nRDST after stage 1. Depending on the dataset, a U-Net model has been ﬁrst trained for medical image segmentation with the same\\ntraining data Ihr∈RsH×sW×Cand the corresponding segmentation labels Lhr:\\nˆθU=argmin\\nθULseg(U(Ihr),Lhr), (7)\\nwhere Uis the segmentation model, θUrepresents its trainable parameters and Lsegis a loss function for segmentation tasks.\\nInspired by previous work on perceptual losses for SISR tasks [Johnson et al. (2016); Ledig et al. (2017); Wang et al. (2018)],\\nwe deﬁne the segmentation-based perceptual loss between two images ( Isr,Ihr) as the L1 distance between their feature maps\\nof certain layers in the pre-trained U-Net. Depending on which layer to be used in the U-Net (Fig. 2), the segmentation-based\\nperceptual loss of ( Isr,Ihr) can be represented as:\\nLE(i)=L1(U[Ei](G(Ilr))−U[Ei](Ihr)), (8)\\nLD=L1(U[D](G(Ilr))−U[D](Ihr)), (9)\\nwhere U[Ei] indicates the i-th block of the encoder and U[D] is the decoder. Furthermore, the perceptual loss can also be deﬁned\\nwith the similarity of predicted segmentation labels of IsrandIhr:\\nLHRL=1−L seg(U(Isr),U(Ihr)). (10)\\nIn this work, we use dice coe ﬃcient [Milletari et al. (2016)] as Lsegto evaluate the distance between two binary segmentation labels\\nXandY, because it is popularly used in medical image segmentation tasks [Ma et al. (2021a)]:\\nDice (X,Y)=2|X⋂Y|\\n|X|+|Y|. (11)\\nDuring model training and ﬁne-tuning, these segmentation-based perceptual loss variants can be used with the native L1loss:\\nLS R=αL1+λLU, (12)\\nwhereαandλare scale factors and LUcan be one or a combination of LE(i),LDandLHRL.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='91095823-3dd4-4bff-acbf-ef4a03462813', embedding=None, metadata={'page_label': '9', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 9\\n4. Experiments\\n4.1. Data and pre-processing\\nFour public medical image datasets are used in this work to evaluate the SR performance and robustness of the proposed method in\\nsimulating the clinical situation as widely as possible. Experiments are designed and applied on: the OASIS [Marcus et al. (2007)]\\ndataset of single-modality brain MR scans; the BraTS [Menze et al. (2015); Bakas et al. (2017, 2018)] dataset of multi-modal\\nbrain MR scans; the ACDC [Bernard et al. (2018)] dataset of cardiac MR images; and the COVID [Ma et al. (2021b)] dataset of\\nchest CT scans. Notice that experiments of ablation studies are mainly conducted with the OASIS dataset because it is clean and\\nrepresentative in the discussion of model architectures, hyper-parameters, loss functions and model e ﬃciency.\\nOASIS We randomly select 39 subjects (30 for training and 9 for testing) from the OASIS-brain dataset2for the×4 super-resolution\\nsimulation experiments. Each subject includes 3 or 4 T1-weighted MRI scans and corresponding segmentation labels of one patient\\nwith early-stage Alzheimer’s Disease (AD). Only one scan (T88-111) is used in this work, with an original size of [176 ×208×176].\\nIt includes plenty of black background regions, providing useless information and slowing down the training process. Thus, the\\noriginal scans and their corresponding segmentation labels are ﬁrst rotated to the axial plane and centrally cropped to 145 slices of\\nsize [160×128]. As a result, the OASIS training dataset includes 4350 slices, and the testing dataset includes 1305 images.\\nBraTS The BraTS dataset3consists of multi-modal MRI scans of 285 patients, including 210 cases with glioblastoma and 75\\ncases with lower grade glioma. Scans of each patient include 4 registered MR modalities: native (T1), post-contrast T1-weighted\\n(T1Gd), T2-weighted (T2) and T2 FLuid Attenuated Inversion Recovery (FLAIR). Manual annotations of the enhancing tumour\\n(ET), the peritumoral edema (ED) and the necrotic and non-enhancing tumour core (NCR /NET) are also provided with each scan. In\\nthis work, we randomly select 120 patients from the BraTS dataset for training and 30 other patients for testing. In pre-processing,\\nonly slices with tumours are chosen for a fair comparison in the downstream segmentation task. As a result, there are 7333 slices\\nfor training and 1853 slices for testing. To remove the pure black background, all slices are centrally cropped to [192 ×192].\\nACDC The ACDC dataset4includes 1.5T and 3.0T cardiac MR scans of 150 patients consisting of 5 evenly divided subgroups: nor-\\nmal subjects, previous myocardial infarction, dilated cardiomyopathy, hypertrophic cardiomyopathy and abnormal right ventricle.\\nAdditionally, the contours of the left ventricle (LV), right ventricle (RV) and myocardium are manually drawn and double-checked\\nby two independent experts with more than 10 years of experience. These segmentation labels of 100 patients are released to the\\npublic. In this work, we randomly divide these 100 patients for training (80 patients with 1462 slices) and testing (20 patients with\\n373 slices). For a fair comparison, all slices are ﬁrst centrally cropped to [128 ×128].\\nCOVID The COVID dataset5includes 3D CT scans with left lung, right lung, and infection annotations of 20 COVID-19 pa-\\ntients. The proportion of infections in the lungs ranges from 0.01% to 59%. Annotations of the left lung, right lung and infection\\nare manually labelled by experienced radiologists. In total, there are 300 +infections with 1800 +slices of various shapes. In this\\nwork, we uniformly crop a [512 ×512] region in the centre of each slice and randomly divide all scans to the training dataset (16\\n2OASIS: https: //www.oasis-brains.org /\\n3BraTS: https: //www.med.upenn.edu /cbica /brats2020 /data.html\\n4ACDC: https: //www.creatis.insa-lyon.fr /Challenge /acdc/databases.html\\n5COVID-19 CT: https: //zenodo.org /record /3757476', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3f176cdd-7d89-446c-ad40-9350dccb5070', embedding=None, metadata={'page_label': '10', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='10 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nscans with 2264 slices) and the testing dataset (4 scans with 588 slices).\\nHR-LR image pair generation The original slices are used as high-resolution ground truth images Ihr∈RH×W×c, and the cor-\\nresponding low-resolution images are generated by down-sampling:\\nIlr=(Ihr⊗k)↓s+n,∀Ihr∈RH×W×c(13)\\nwhere kis a bicubic down-sampling kernel and nis an additive Gaussian noise. we focus on ×4 super-resolution tasks in this work,\\nso the HR and LR patches are cropped with size [96 ×96] and [24×24], respectively.\\n4.2. Evaluation Metrics\\nIn addition to Peak Signal-to-Noise Ration (PSNR) and Structural Similarity (SSIM), the SR results of the proposed RDST and\\nSOTA methods are also evaluated in downstream segmentation tasks. As described in Section 3.2, we ﬁrst train a segmentation\\nU-Net for each dataset with HR images in the training subset and their corresponding ground truth segmentation labels. Take the\\nOASIS dataset as an example. The pre-trained U-Net achieves high segmentation performance on HR images in the testing dataset,\\nso the segmentation-based SR performance measurement can be reliable. To evaluate the SR results of SOTA methods and the\\nproposed RDST variants, we use dice coe ﬃcients of the whole region and tissues depending on each dataset. For example, the\\nexperiments with the OASIS dataset involve the dice coe ﬃcient scores on the whole brain (Dice-T), grey matter (Dice-G), white\\nmatter (Dice-W) and cerebrospinal ﬂuid (Dice-CSF):\\nPsr=U(Isr),\\nDice-T =Dice (Psr,LGT),\\nDice-G =Dice (Psr[CG],LGT[CG]),\\nDice-W =Dice (Psr[CW],LGT[CW]),\\nDice-CSF =Dice (Psr[CCS F],LGT[CCS F]), (14)\\nwhere CG,CW, and CCS Fare label indexes of grey matter, white matter and CSF, respectively. Similarly, we use dice coe ﬃcient\\nscores of the left ventricular cavity (Dice-LV), the right ventricular cavity (Dice-RV), the myocardium (Dice-MC) and the whole\\nregion (Dice-T) for the ACDC dataset and the dice coe ﬃcient scores of the left lung (Dice-LL), the right lung (Dice-RL), the\\nlesion (Dice-Lesion) and the whole region (Dice-T) for the COVID dataset. In the experiments with the BraTS dataset, we use dice\\ncoeﬃcient scores of the enhancing tumour (Dice-ET, including ET only), the tumour core (Dice-TC, including ET and NCR /NET)\\nand the whole tumour (Dice-WT, including ET, ED and NCR /NET).\\n4.3. Implementation details\\nThe proposed RDST and SOTA models are implemented with PyTorch [Paszke et al. (2019)]. All experiments were performed\\non an Nvidia Quadro RTX 8000 GPU. Inspired by SwinIR [Liang et al. (2021)], the window size, attention head number and the\\nbasic feature embedding dimension are set to [8 ×8], 6 and 60, respectively. As mentioned in Section 3.1, each RDSTB module\\nconsists of 3 DSTBs with a growth rate of 30. Each DSTB module consists of 2 STLs. In this work, we propose two RDST\\nvariants. The original one consists of 8 RDSTBs, while the more e ﬃcient version (RDST-E) consists of only 4 RDSTBs. In the\\nexperiments, all parameters are initialised by Kaiming-uniform [He et al. (2015b)] and optimised by the Adam optimiser [Kingma', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='22842201-7d6d-473b-a948-5f7f4c2fe281', embedding=None, metadata={'page_label': '11', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 11\\nFig. 3. Comparing RDST and RDST-E with SOTA SISR methods on ×4super-resolution task with the OASIS dataset. The PNSR (the X-axis) indicates the\\nSR image quality, while the dice scores (the Y-axis) represent the downstream segmentation performance. Dice-[T, G, W, CSF] specify the dice coe ﬃcient\\nof whole brains, grey matter, white matter and cerebrospinal ﬂuid, respectively. The best PSNR and dice scores are pointed out. Bigger symbols indicate\\nmore parameters of the models.\\nFig. 4. Comparing RDST with SOTA methods on ×4super-resolution task with OASIS dataset. SR results and corresponding segmentation predictions\\nof a randomly selected slice are shown with PSNR and dice coe ﬃcient of the whole brain. In the segmentation labels, grey, yellow and cyan indicate grey\\nmatters, white matters and CSFs, respectively, and segmentation errors are marked as red.\\nand Ba (2014)]. we set the batch size to 32 for each step for both training stages. In the ﬁrst training stage, the initial learning\\nrate is set to 0.0002 with no decay, and the RDST is trained for 100k steps with only native L1loss. The ﬁne-tuning stage in-\\ncludes 20k steps. Its learning rate is initialised as 0.0001 and halved at [10k ,15k,17.5k]. The scale factors in Equation 12 are set\\nasα=1,λ=10 to ensure the segmentation-based perceptual loss dominates the ﬁne-tuning stage. The L1 distance between fea-\\nture maps of the ﬁrst encoder block LE(1)is mainly used as the perceptual loss, and other variations of LUare used in ablation study.\\nThe segmentation U-Net model is implemented with Segmentation-Models-PyTorch [Iakubovskii (2019)]. It consists of 5 ResNet-\\nbased [He et al. (2015a)] encoder blocks and a decoder of native convolutional layers (Fig. 2). The channel number is set to 64\\nbasically and doubled after each encoder block. This model is trained with Dice loss (Equation 10) for 100k steps with the Adam\\noptimiser. The learning rate is initialised as 0.0001 and halved at [50k ,75k].', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c4dd65cb-009d-412f-8e21-4652893387a8', embedding=None, metadata={'page_label': '12', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='12 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nTable 1. Compare RDST with SOTA methods on the OASIS dataset. The best and second-best scores are highlighted in red and blue respectively. MACs\\nare calculated with an input size [1×40×32×1].\\nMean(std) PSNR(dB)↑SSIM↑ Dice-T↑ Dice-G↑ Dice-W↑ Dice-CSF↑ MACs(G)↓params(M)↓\\nHR 0.9520(0.012) 0.9401(0.040) 0.9399(0.013) 0.9408(0.015)\\nBicubic 29.88(2.7) 0.8574(0.052) 0.8125(0.0088) 0.7179(0.075) 0.8137(0.021) 0.8207(0.016)\\nEDSR 32.55(3.5) 0.9184(0.039) 0.8784(0.0098) 0.8334(0.055) 0.8586(0.021) 0.8807(0.015) 64.22 43.08\\nRDN 32.57(3.2) 0.9241(0.036) 0.8802(0.010) 0.8316(0.059) 0.8620(0.021) 0.8845(0.015) 7.95 5.76\\nRCAN 32.81(3.6) 0.9224(0.038) 0.8828(0.0094) 0.8424(0.054) 0.8619(0.021) 0.8831(0.013) 41.34 32.03\\nHAN 32.33(3.7) 0.9120(0.042) 0.8751(0.0091) 0.8317(0.055) 0.8534(0.022) 0.8776(0.015) 83.86 64.19\\nSwinIR 33.24(3.7) 0.9287(0.036) 0.8888(0.0097) 0.8506(0.054) 0.8688(0.020) 0.8880(0.015) 14.68 11.47\\nRDST-E 33.26(3.4) 0.9291(0.035) 0.8871(0.0096) 0.8446(0.057) 0.8686(0.020) 0.8877(0.015) 3.53 2.35\\nRDST 33.42(3.7) 0.9299(0.035) 0.8889(0.0097) 0.8514(0.054) 0.8688(0.021) 0.8874(0.015) 6.17 4.40\\n5. Results and discussion\\nIn this section, we ﬁrst illustrate the superior performance of the proposed RDST variants compared with SOTA SISR methods on\\nfour medical image datasets, then discuss the key factors of RDST twofold: the novel architecture and the new segmentation-based\\nperceptual loss.\\n5.1. Comparing RDST with SOTA methods\\nTwo variations of RDST are compared with 5 popular and representative state-of-the-art SISR methods, including: (1). pure convo-\\nlutional methods EDSR [Lim et al. (2017)] and RDN [Zhang et al. (2018b)]; (2) CNN based attention models RCAN [Zhang et al.\\n(2018a)] and HAN [Niu et al. (2020)]; and (3) self-attention-based vision transformers SwinIR [Liang et al. (2021)]. Additionally,\\nwe have done experiments with related SR methods in a wider range, such as zero-shot super-resolution [Shocher et al. (2017)],\\nscale-free super-resolution [Hu et al. (2019); Zhu et al. (2021b)] and pre-trained ViT [Chen et al. (2021)]. However, we ﬁnally\\ndecided not to involve these methods in the comparison because of their mediocre performance.\\nRDST variants achieve the best image quality on all four datasets. Speciﬁcally, RDST-E achieves the best PSNR performance\\non the ACDC dataset, and RDST achieves the best PSNR scores on the OASIS dataset, the COVID dataset and every MR modal-\\nity in the BraTS dataset. On average, RDST increases by 0.09dB in PSNR, and RDST-E leads to a 0.06dB increase compared\\nwith the most recent SOTA method SwinIR. Meanwhile, we clearly show that improving image quality can lead to signiﬁcantly\\nbetter performance in the downstream segmentation tasks. With the well-trained U-Net segmentation models and introducing the\\nsegmentation-based SR results evaluation, SOTA SISR methods considerably narrow the gap of segmentation accuracy between HR\\nGT images and×4 bicubic interpolated images. In summary, RDST achieves the best dice coe ﬃcient scores of 8 targeted regions\\namong all 15 regions. Detailed results of each dataset are as follows.\\nPerformance on the OASIS dataset RDST achieves the best performance of almost all metrics in the ×4 super-resolution ex-\\nperiment with the OASIS dataset (Fig. 3). It brings noticeable improvements in image quality ( +0.18dB PSNR and +0.0012 SSIM)\\nto SwinIR. In the downstream segmentation task, SR results of RDST get the best dice coe ﬃcient scores of the whole brain, the\\ngrey matter and the white matter (Table 1). The pre-trained U-Net achieves reliable segmentation performance on HR GT images. It\\nclearly shows a notable decline with native bicubic interpolation SR results: [0 .1395,0.2210,0.1262,0.1201] on whole brains, grey\\nmatters, white matters and CSFs, respectively. The proposed RDST narrows these gaps by [0 .0774,0.1335,0.0551,0.0667] respec-\\ntively. Notice that room for improvement exists as the best segmentation dice scores of all SR images are still signiﬁcantly lower\\nthan HR images ([ −0.0621,−0.0887,−0.0711,−0.0518]). On the other hand, the smallest model RDST-E achieves the second-best', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c2ee95ce-5795-416f-85c9-963fdbcf878b', embedding=None, metadata={'page_label': '13', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 13\\nFig. 5. SR results of a random slice in the testing subset of BraTS. SR results of whole slices are generated, but only the regions within the tumour of the\\nfour modalities are plotted with predicted labels in the downstream segmentation task for better comparison. Annotations of tumour sub-regions are the\\nnecrotic and the non-enhancing (NCR & NET) parts of the tumour in yellow, the peritumoral edema (ED) in cyan and the enhancing tumour in grey.\\nSegmentation errors are indicated in red. PSNR and dice coe ﬃcient of the whole tumour (Dice-WT) are also displayed.\\nPSNR and SSIM scores with a slight decrease in segmentation performance. While visualising the SR results and their correspond-\\ning segmentation predictions, the segmentation labels can help determine the di ﬀerences between SR images of SOTA methods,\\nwhich are di ﬃcult to recognise with only the images. Vision transformers (i.e. SwinIR and RDST) achieve superior image quality\\non edges than CNNs (green box in Fig. 4). On the other hand, it is still challenging for all methods to reconstruct rich textures of\\nsmall regions (red box in Fig. 4).\\nModel e ﬃciency Additionally, we compare the model e ﬃciency in the experiment on the OASIS dataset by calculating the number\\nof parameters and the Multi-Add Calculations (MACs) with an [1 ×40×32×1] input (Table 1). RDST-E is the smallest and requires\\nthe fewest MACs, while RDST is the second smallest and requires fewer calculations than SOTA methods. Compared with SwinIR,\\nRDST has only 38% parameters, and RDST-E has only 20% parameters. As a result, they reduce the computational cost by 58%\\nand 76%, respectively.\\nPerformance on the BraTS dataset Doing×4 super-resolution in the multi-modal brain tumour segmentation dataset is more\\nchallenging for the following reasons. First, the super-resolution method must be synchronously applied on four registered MR\\nscans (i.e. T1Gd, T1, T2 and T2-FLAIR) so the input and output layers of RDST variants and SOTA methods are modiﬁed. Second,\\nthe downstream multi-modal tumour issue segmentation is challenging, and the U-Net with poor segmentation performance may\\nmisdirect the ﬁne-tuning stage. In this experiment, the pre-trained U-Net has achieved dice coe ﬃcients of [0.7830,0.6919,0.6820]\\non the whole tumour, the enhancing tumour and the tumour core, respectively. Compared with bicubic interpolation, SOTA deep\\nneural networks signiﬁcantly improve the SR performance (Table. 2) on image quality and downstream segmentation performance.\\nThe proposed RDST achieves the best PSNR scores on all modalities, and the e ﬃcient version RDST-E achieves the second-best\\nscores on three modalities (i.e. T1Gd, T1 and T2-FLAIR). SwinIR, the SOTA vision transformer for SISR tasks, also performs\\nbetter than CNN models. It dominates the SSIM scores with RDST. On average, RDST gets +0.13dB higher PSNR than SwinIR\\nand equal SSIM (-0.0003) of the four modalities. In the downstream tumour segmentation task, RDST achieves the best dice coef-\\nﬁcients of the whole tumours and the enhancing tumours. EDSR achieves the best segmentation performance of the tumour cores.\\nInterestingly, SR results of SwinIR and RDST can even provide more accurate segmentation labels than HR GT images, probably\\nbecause the down-sample and super-resolve process removes some noises and misleading textures. Similar to the experiments on\\nthe OASIS dataset, the segmentation labels help to recognise the most challenging part in the SR image generation: reconstructing', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3e4a6b70-1a94-4630-8539-a4f7e6946444', embedding=None, metadata={'page_label': '14', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='14 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nFig. 6. SR results of a random slice in the testing dataset of ACDC. Accurate segmentation predictions are annotated in grey (the RV cavity), yellow (the\\nmyocardium) and cyan (the LV cavity), while wrong predictions are annotated in red. PSNR scores and dice coe ﬃcients of the whole region are shown.\\nthe blur edges and irregular textures (Fig. 5).\\nPerformance on the ACDC dataset Single image SR of cardiac MR images is challenging because the motion artefacts caused by\\npatients’ atrial ﬁbrillation during the scanning procedure are individual and hard to resolve. As a result, data-driven deep learning\\nmethods can rarely bring a dramatic improvement in PSNR than traditional interpolation methods. In the comparison study of ×4\\nmagniﬁcation (Table. 3), SOTA methods, including RDST variants, increase PSNR from +0.80 dB to +1.10 dB than bicubic inter-\\npolation. In contrast, SOTA SISR methods can easily lead to more than 3 dB improvement of PSNR on other datasets. Additionally,\\nbecause the training data is limited (only 1462 slices with size [128 ×128]), over-ﬁtting may happen. As a result, the smallest model\\nRDST-E achieves a signiﬁcant advantage of PSNR ( +0.20 dB higher than other methods). However, it is hard to evaluate the SR\\nperformance with only PSNR because most methods achieve very close scores from 27.03 dB to 27.06 dB. we guess the low PSNR\\nscores of RDST and SwinIR are caused by the over-ﬁtting of background noise, which leads to substantial pixel-wise errors but\\nrare impacts in segmentation and visualisation (Fig. 6). In contrast, evaluating SR results with the dice coe ﬃcient scores and SSIM\\nscores is more e ﬀective and robust. The segmentation U-Net is well-trained for the ACDC dataset with reliable performance on HR\\nGT images. Meanwhile, the segmentation-based evaluation represents the global structure reconstruction accuracy in SR results.\\nIn this experiment, vision transformers (i.e. SwinIR, RDST-E and RDST) achieve the highest SSIM and perform the best in the\\ndownstream segmentation task, so we claim that they are better than the CNN-based methods.\\nPerformance on the COVID dataset We also extend the proposed method to CT images. Compared with MR scans, CT scans are\\nwith higher resolution (e.g. [512 ×512]) and fewer artefacts. All methods achieve very close PSNR (from 34.56 dB to 34.70 dB)\\nand SSIM (from 0.8678 to 0.8707) scores in the ×4 SR experiment (Table. 4). Speciﬁcally, RDST achieves the highest PSNR score\\nand the best segmentation results of the whole region and the right lung. Meanwhile, RCAN achieves the best SSIM, and HAN\\nachieves the best segmentation accuracy of the left lung and the lesion. Notice that both methods are with very deep architectures\\n(>800 layers) and with more than 30M parameters, which may beneﬁt the reconstruction of the textures in lesion areas (Fig. 7).\\n5.2. Network architecture, attention and inference e ﬃciency\\nAn ablation study is designed to ﬁgure out the critical factors of RDST variants that achieve superior performance than SOTA SISR\\nmethods on the OASIS dataset. PSNR, SSIM and dice coe ﬃcient of the whole brain are used as SR image evaluation metrics.\\nMeanwhile, the numbers of MACs and parameters and the throughout frame rate during inference are used to measure the model\\neﬃciency. All methods are trained with the same settings (100k steps with L1only) to avoid the impacts of the segmentation-based', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='23573ecd-d052-41e6-8344-b84f71583531', embedding=None, metadata={'page_label': '15', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 15\\nFig. 7. SR results of a random slice in the testing dataset of COVID-CT. PSNR scores and dice coe ﬃcients of the lesion are shown. Accurate segmentation\\npredictions are annotated in grey (the left lung), yellow (the right lung) and cyan (the lesion), while wrong predictions are annotated in red. Patches of two\\nsub-regions are zoomed in for better visualisation.\\nTable 2. Comparing RDST with SOTA methods in the ×4super-resolution task on the BraTS dataset. PSNR and SSIM scores are calculated on each\\nmodality (i.e. one of T1Gd, T1, T2, and T2-FLAIR) and averaged. Dice coe ﬃcients of the whole tumour (WT), the enhancing tumour (ET) and the tumour\\ncore (TC) are used in the downstream segmentation evaluation with the pre-trained 2D U-Net. The best and the second best scores are highlighted in red\\nand blue, while∗indicates superior segmentation performance than HR GT images.\\nMean(std) Dice↑ PSNR↑ SSIM↑\\nWT ET TC T1Gd T1 T2 Flair T1Gd T1 T2 Flair\\nHR 0.7833(0.13) 0.6919(0.13) 0.6820(0.16)\\nBicubic 0.7614(0.12) 0.5226(0.20) 0.5878(0.18) 29.97(1.9) 29.04(2.3) 28.19(2.1) 29.33(2.4) 0.8571(0.035) 0.8661(0.037) 0.8509(0.037) 0.8362(0.047)\\nEDSR 0.7800(0.12) 0.6854(0.12) 0.6776(0.16) 32.63(2.0) 32.36(2.4) 31.08(1.9) 31.89(2.4) 0.9143(0.024) 0.9271(0.025) 0.9156(0.024) 0.8968(0.033)\\nRDN 0.7806(0.12) 0.6874(0.13) 0.6729(0.17) 32.97(2.0) 32.73(2.4) 31.48(2.0) 32.29(2.4) 0.9193(0.024) 0.9320(0.024) 0.9218(0.024) 0.9039(0.032)\\nRCAN 0.7815(0.12) 0.6808(0.12) 0.6674(0.17) 32.84(2.0) 32.59(2.4) 31.29(2.0) 32.14(2.3) 0.9183(0.023) 0.9310(0.024) 0.9202(0.023) 0.9022(0.032)\\nHAN 0.7801(0.12) 0.6833(0.12) 0.6722(0.17) 32.56(1.9) 32.24(2.4) 31.03(1.9) 31.84(2.3) 0.9155(0.024) 0.9281(0.024) 0.9168(0.024) 0.8976(0.033)\\nSwinIR 0.7836*(0.12) 0.6816(0.12) 0.6710(0.16) 33.23(2.1) 33.03(2.5) 31.73(2.0) 32.54(2.4) 0.9226(0.023) 0.9350(0.024) 0.9253(0.023) 0.9082(0.031)\\nRDST-E 0.7831(0.12) 0.6832(0.12) 0.6713(0.18) 33.32(2.0) 33.13(2.4) 31.71(2.1) 32.59(2.4) 0.9218(0.024) 0.9339(0.025) 0.9231(0.024) 0.9066(0.032)\\nRDST 0.7836*(0.12) 0.6883(0.12) 0.6713(0.17) 33.37(2.0) 33.22(2.5) 31.81(2.1) 32.63(2.4) 0.9227(0.023) 0.9350(0.024) 0.9248(0.023) 0.9075(0.032)\\nTable 3. Comparing RDST with SOTA methods in the ×4super-resolution task on the ACDC dataset. In addition to PSNR and SSIM, dice coe ﬃcients of\\nthe total region (T), the left ventricular cavity (LV), the right ventricular cavity (RV), and the myocardium (MC) in the downstream segmentation task are\\nused for evaluation. The best and the second-best scores are highlighted in red and blue respectively.\\nMean(std) PSNR↑ SSIM↑ Dice-T↑ Dice-LV↑ Dice-RV↑ Dice-MC↑\\nHR 0.8932(0.027) 0.9184(0.034) 0.7390(0.11) 0.8783(0.036)\\nBicubic 26.14(2.7) 0.7501(0.053) 0.8096(0.051) 0.8717(0.059) 0.5927(0.15) 0.7697(0.058)\\nEDSR 26.94(3.1) 0.7722(0.064) 0.8599(0.030) 0.8950(0.044) 0.6897(0.12) 0.8354(0.044)\\nRDN 27.07(3.0) 0.7854(0.058) 0.8624(0.029) 0.8979(0.038) 0.6946(0.12) 0.8376(0.039)\\nRCAN 27.06(3.0) 0.7819(0.061) 0.8657(0.030) 0.8947(0.044) 0.6867(0.14) 0.8399(0.042)\\nHAN 27.06(3.4) 0.7738(0.069) 0.8666(0.030) 0.8946(0.043) 0.6971(0.13) 0.8419(0.046)\\nSwinIR 27.04(3.1) 0.7876(0.059) 0.8705(0.026) 0.9001(0.043) 0.6964(0.12) 0.8456(0.039)\\nRDST-E 27.24(3.0) 0.7940(0.057) 0.8691(0.025) 0.8954(0.043) 0.7008(0.12) 0.8454(0.035)\\nRDST 27.03(3.1) 0.7875(0.059) 0.8691(0.027) 0.8959(0.043) 0.7071(0.11) 0.8433(0.035)', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='d013b5cb-65f7-420a-8506-9c1b6c219979', embedding=None, metadata={'page_label': '16', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='16 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nTable 4. Comparing RDST with SOTA methods in the ×4super-resolution task on the COVID-CT dataset. In addition of PSNR and SSIM, dice coe ﬃcients\\nof the total region (T), the left lung (LL), the right lung (RL), and the lesion in the downstream segmentation task are used for evaluation. The best and the\\nsecond best scores are highlighted in red and blue respectively.\\nMean(std) PSNR↑ SSIM↑ Dice-T↑ Dice-LL↑ Dice-RL↑ Dice-Lesion↑\\nHR 0.8762(0.11) 0.8553(0.17) 0.8905(0.10) 0.6554(0.035)\\nBicubic 28.45(3.0) 0.7760(0.15) 0.8092(0.12) 0.7386(0.17) 0.8430(0.11) 0.3848(0.14)\\nEDSR 34.59(4.4) 0.8694(0.15) 0.8315(0.18) 0.8265(0.20) 0.8713(0.13) 0.5881(0.14)\\nRDN 34.56(4.4) 0.8678(0.15) 0.8196(0.19) 0.8167(0.21) 0.8590(0.14) 0.5674(0.13)\\nRCAN 34.69(4.4) 0.8707(0.15) 0.8365(0.17) 0.8175(0.21) 0.8684(0.13) 0.6207(0.11)\\nHAN 34.65(4.4) 0.8700(0.15) 0.8323(0.18) 0.8294(0.19) 0.8695(0.13) 0.6247(0.18)\\nSwinIR 34.66(4.5) 0.8698(0.15) 0.8299(0.18) 0.8201(0.20) 0.8678(0.13) 0.5846(0.12)\\nRDST-E 34.62(4.5) 0.8678(0.15) 0.8264(0.19) 0.8134(0.21) 0.8620(0.15) 0.5709(0.088)\\nRDST 34.70(4.5) 0.8687(0.15) 0.8445(0.16) 0.8281(0.19) 0.8761(0.13) 0.5884(0.085)\\nFig. 8. An ablation study on the hyperparameters of RDST: (a) impacts of the window size, varying in [2, 4, 8]; (b) impacts of the feature map embedding\\ndimension, varying from 24 to 132; (c) impacts of the number of swin transformer layers (STLs) in the dense block, varying from 2 to 8; (d) impacts of the\\nnumber of DSTBs in each RDSTB, varying from 2 to 5; (e) impacts of the number of RDSTBs in RDST, varying from 2 to 12.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='961838f9-8cba-4cc9-9126-b1062e81bb5c', embedding=None, metadata={'page_label': '17', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 17\\nperceptual loss and additional training steps.\\nNetwork architecture Comparing RDST variants and SOTA methods, the main di ﬀerences in network architecture are fourfold.\\nFirst, a model can be created with only convolutional layers or a hybrid of transformers (e.g. STL) and CNNs. Second, the window\\nsize, which presents the receptive ﬁeld of each layer, can be di ﬀerent. Third, the model widths, which indicate the feature map\\ndimensions, vary from 64 to 256. Fourth, one network can be shallow (e.g. EDSR-lite with only 32 layers) or deep (e.g. HAN with\\n1610 layers). Thus, we divide all methods into four groups: (1) native CNN SISR methods, including EDSR and RDN; (2) native\\nCNN models with large window size, which are implemented based on ConvNet [Liu et al. (2022)]; (3) deep CNN models with\\nmore than 800 layers, i.e. RCAN and HAN; and (4) STL based vision transformers such as SwinIR and RDST. we propose the\\nConvNet-based SISR method to discuss the impacts of the receptive ﬁeld [Luo et al. (2016)], which is considered the critical factor\\nfor the success of vision transformers [Ding et al. (2022)]. Meanwhile, the lite versions of EDSR, SwinIR and ConvNet are also\\ninvolved in comparing small SISR models with RDST-E.\\nSTL or CNN? First, vision transformers show more dramatically improved SR image quality and segmentation accuracy than\\nCNN methods. Notice that SwinIR and RDST variants are all based on the Swin transformer layer, which learns from the shared\\nweights and localised operation of convolutional layers. Additionally, CNN layers are used at intervals of STL blocks which further\\nensures the training stability of these hybrid methods and leads to superior performance than pure CNN methods. Second, the larger\\nwindow size failed to extend the success with transformers to CNN models. Both versions of the ConvNet-based methods perform\\nworse than all the other methods. In deep networks, the receptive ﬁeld depends on the window size in one layer and the number of\\nlayers. Thus, deeper networks with small window sizes can have an equal receptive ﬁeld with shallow networks with large window\\nsizes. For CNNs, the former works better probably because more non-linear activation is essential for feature extraction. Third,\\ndeeper models consistently achieve better results in each group with similar network architectures. Notice that both increases in\\nwidth and depth lead to an increase in parameters and an e ﬃciency decrease. In this comparison study on medical image SR tasks,\\nincreasing the number of blocks is more e ﬀective. For example, RDST has more layers and a smaller width than SwinIR, leading\\nto fewer computational costs and parameters. It ﬁnally achieves equal PSNR ( +0.01 dB) and SSIM (-0.0001) scores with only 38%\\nparameters of SwinIR.\\nHyperparameters Additionally, experiments are designed on RDST-E to ﬁgure out the impacts of hyperparameters of RDST (Fig.\\n8). In RDST there is a gradual growth of feature map dimension because of the dense connections. we take the dimension after\\nlocal feature fusion as the model width. On the other hand, a deeper RDST can be created by increasing three factors: the number\\nof Swin transformer layers in the DSTB modules, the number of DSTBs and the number of RDSTBs. Brieﬂy speaking, increasing\\nthe number of RDSTB modules, the window size and the model width in an adequate range can improve SR image quality.\\nAttention The attention mechanism is brieﬂy regarded as threefold depending on where it works: channel attention, spatial at-\\ntention and layer attention (Table. 5). Notice that the global feature fusion in RDN [Zhang et al. (2018b)] is considered elementary\\nlayer attention, and the self-attention in transformers is considered a super-set of both channel and spatial attention. Attention\\nin CNN models raises training stability and leads to very deep networks but rarely improves the medial image super-resolution\\nperformance. For example, RCAN has 811 layers, and HAN has 1610 layers, but neither performs superior to other methods. On', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='689f0051-8079-4acb-9e99-d95e2a922e57', embedding=None, metadata={'page_label': '18', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='18 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nTable 5. Ablation study on the OASIS dataset to answer why transformers perform better than CNNs. PSNR, downstream segmentation dice score of the\\nwhole brain (Dice-T) and inference frame rate (FPS) are used as evaluation metrics for both image quality and model e ﬃciency. The best (in red) and\\nsecond-best (in blue) scores are in bold. All methods are divided into four groups: (1). native CNN methods include EDSR and RDN; (2). the proposed\\nConvNet-based SR methods with the large receptive ﬁelds in CNN; (3). very deep CNNs with attention; and (4). methods with Swin transformer layers.\\nNotice that the global feature fusion (GFF) in RDN and RDST variants is considered elementary hierarchical attention, while self-attention in transformers\\nis considered a superset of both channel and spatial attention. Very wide (dimensions ≥128) and deep (layers ≥128) networks are in bold.\\nNetwork Architecture Attention Performance Eﬃciency\\nLayer Window Width Depth Channel Spatial Layer PSNR↑ SSIM↑ Dice-T↑ MACs(G)↓params(M)↓ FPS↑\\nEDSR-lite CNN 3×3 64 32 \\x17 \\x17 \\x17 32.40(3.1) 0.9192(0.037) 0.8766(0.0099) 2.51 1.52 325.02\\nEDSR CNN 3×3 256 64 \\x17 \\x17 \\x17 32.55(3.5) 0.9184(0.039) 0.8784(0.0098) 64.22 43.08 88.00\\nRDN CNN 3×3 64→256 142 \\x17 \\x17 \\x13 32.57(3.2) 0.9241(0.036) 0.8802(0.010) 7.95 5.76 70.89\\nConvNet-lite CNN 7×7 64 48 \\x17 \\x17 \\x17 31.92(2.9) 0.9111(0.039) 0.8669(0.010) 1.69 0.88 213.54\\nConvNet-large CNN 7×7 192 96 \\x17 \\x17 \\x17 32.14(3.3) 0.9130(0.040) 0.8733(0.010) 21.00 12.43 98.79\\nRCAN CNN 3×3 64 1610 \\x13 \\x17 \\x17 32.81(3.6) 0.9224(0.038) 0.8828(0.0094) 41.34 32.03 6.38\\nHAN CNN 3×3 128 811 \\x13 \\x13 \\x13 32.33(3.7) 0.9120(0.042) 0.8751(0.0091) 83.86 64.19 17.01\\nSwinIR-lite STL+CNN 8×8 60 101 \\x13 \\x13 \\x17 32.87(3.2) 0.9252(0.037) 0.8836(0.0095) 1.15 0.88 30.12\\nSwinIR STL+CNN 8×8 180 150 \\x13 \\x13 \\x17 33.24(3.7) 0.9287(0.036) 0.8888(0.0097) 14.68 11.47 19.45\\nRDST-E(L1) STL+CNN 8×8 60→150 114 \\x13 \\x13 \\x17 33.06(3.3) 0.9278(0.035) 0.8869(0.0091) 3.53 2.35 28.47\\nRDST(L1) STL+CNN 8×8 60→150 226 \\x13 \\x13 \\x17 33.25(3.5) 0.9286(0.035) 0.8880(0.0097) 6.17 4.40 13.93\\nRDST +GFF(L1)STL+CNN 8×8 60→150 228 \\x13 \\x13 \\x13 33.23(3.5) 0.9290(0.035) 0.8887(0.0095) 6.17 4.40 13.89\\nFig. 9. A RDST variant with MLP-based global feature fusion (GFF).\\nFig. 10. Ablation study on model architectures and attention mechanisms. All models are divided into 5 groups: native CNNs in blue, CNNs with a large\\nreceptive ﬁeld in yellow, CNN-based attention models in green, SwinIR variations in light blue and the proposed RDST variations in red. PSNR scores\\n(the x-axis) and dice coe ﬃcients of the whole brain in the downstream segmentation task (Dice-T, the y-axis) are used as evaluation metrics for SR image\\nquality. Bigger symbols indicate higher inference throughout frame rates. For a fair comparison, all models apply the same training settings ( L1only for\\n100k steps with no extra ﬁne-tuning).', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='c4db06c4-374b-48b3-aa51-6518d34d9f25', embedding=None, metadata={'page_label': '19', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 19\\nthe other hand, the self-attention in vision transformers, which introduce dynamic parameters to the whole computation process,\\ndramatically improves the SR performance as in SwinIR [Liang et al. (2021)] and RDST variations. Meanwhile, the GFF module\\nhas no noticeable improvement or decline in SR results, so it is abandoned in the ﬁnal design of RDST.\\nInference frame rate In addition to the number of parameters and calculations (MACs), we introduce the inference frame rate\\n(FPS) as a more straightforward evaluation of model e ﬃciency. Compared with MR and CT scanning in the clinic, all methods can\\nalmost real-time (at least 6 slices per second on an Nvidia RTX 8000 GPU for [40 ×32×1]→[160×128×1] SR. In addition\\nto MACs and parameters, the inference e ﬃciency depends on GPU acceleration and model architecture. Thus, transformers are\\ngenerally slower than CNNs, although they have fewer parameters. Additionally, the depth of each model plays a crucial role in\\ninference e ﬃciency because it cannot be executed in parallel. For example, RCAN is the slowest model as it has the most layers.\\nAmong the vision transformers, RDST has fewer parameters and requires less computation but is slower than SwinIR because of\\nmore layers. The main advantage of vision transformers is that self-attention activates the capability of parameters more adequately,\\nso superior performance is achieved with less computation and shallower networks. With potential hardware acceleration support\\nin the future, transformers may be smaller and faster than CNNs. Speciﬁcally, RDST-E has a similar size to the lite version model\\n(e.g. EDSR-lite and SwinIR-lite) but achieves comparable performance with regular SISR methods such as SwinIR.\\n5.3. Impacts of the segmentation-based perceptual loss\\nIn this section, we discuss the impacts of the proposed segmentation-based perceptual loss LUwith the following questions:\\n1. Is the segmentation-based perceptual loss better than existing perceptual and adversarial losses?\\n2. Feature maps of which layer in the pre-trained U-Net should be used?\\n3. What connection has been created with this perceptual loss between super-resolution and segmentation tasks?\\n4. Can this perceptual loss improve SR performance with other SISR methods?\\n5. How can this segmentation-based perceptual loss be extended to datasets without segmentation labels?\\nTo answer these questions (Table. 6), an RDST-E model is trained for 100k steps with only L1as the Baseline and then ﬁne-tuned\\nfor extra 20k steps with di ﬀerent combinations of L1and perceptual losses. To avoid the impacts of the additional training steps,\\nwe further train an RDST-E with L1for the same steps (so-called ” L1only”).\\nComparison with L1, VGG and WGANGP The shallow feature map based perceptual loss LE(1)achieves the best SR image\\nquality in all models. It results in signiﬁcant increases of PSNR ( +0.20 dB) and SSIM ( +0.0013) than the Baseline (100k-steps\\ntraining with only L1) and +0.14 dB PSNR and +0.0005 SSIM comparing with the 120k-steps L1model, so the improvement is\\nmainly caused by the proposed loss function but not the extra training steps. In contrast, neither the VGG-based perceptual loss\\nnor the WGANGP loss combination can lead to better image quality. Actually, in the experiments, we have tested a big range\\n(0.0001<γ< +∞) of the scale factor of the VGG-based perceptual loss when using it with the L1loss (L1+γLVGG) and ﬁnd that\\nall the combinations decline the image quality in the medical image SR task.\\nComparison ofLUvariations As mentioned in Section 3.2, variants of the segmentation-based perceptual loss are deﬁned de-\\npending on the choice of feature maps in the U-Net. Generally, researchers agree that shallow layers represent local and basic\\nfeatures while deep layers represent global and semantic information in networks. we conduct experiments to compare the LU', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='725e795e-4031-4be6-aeee-af78ab425b9d', embedding=None, metadata={'page_label': '20', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='20 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nTable 6. Ablation study of the segmentation-based perceptual loss variations. LE(i)indicates the native L1 distance between the feature maps of the i-th\\nencoder block, while∑5\\n1LE(i)indicates the sum. L1 distance between the outputs of the decoder ( LD) and the dice loss of predicted labels ( LHRL) are also\\ntested. The best (in red) and the second best (in blue) scores are in bold.\\nMean(std) PSNR↑ SSIM↑ FID↓Dice-T↑ Dice-G↑ Dice-W↑ Dice-CSF↑\\nBaseline 33.06(3.3) 0.9278(0.035) 81.63 0.8869(0.0091) 0.8438(0.057) 0.8685(0.020) 0.8877(0.014)\\nL1only 33.12(3.4) 0.9286(0.035) 81.30 0.8874(0.0094) 0.8453(0.057) 0.8688(0.020) 0.8880(0.014)\\nWGANGP +VGG 33.06(3.4) 0.9259(0.037) 72.64 0.8885(0.0094) 0.8480(0.055) 0.8692(0.020) 0.8883(0.014)\\nVGG only 33.12(3.4) 0.9277(0.036) 70.83 0.8880(0.0092) 0.8471(0.056) 0.8689(0.020) 0.8882(0.014)\\nLE(1) 33.26(3.4) 0.9291(0.035) 82.13 0.8871(0.0096) 0.8446(0.057) 0.8686(0.020) 0.8877(0.015)\\nLE(2) 32.56(3.3) 0.9165(0.040) 73.07 0.8858(0.0089) 0.8484(0.052) 0.8650(0.020) 0.8854(0.015)\\nLE(3) 32.53(3.3) 0.9181(0.040) 74.83 0.8855(0.0087) 0.8483(0.051) 0.8643(0.021) 0.8843(0.014)\\nLE(4) 32.31(3.2) 0.9138(0.041) 82.77 0.8845(0.0087) 0.8473(0.051) 0.8630(0.021) 0.8849(0.014)\\nLE(5) 32.04(3.2) 0.9061(0.041) 87.01 0.8830(0.0079) 0.8473(0.049) 0.8609(0.021) 0.8821(0.013)\\nL∑5\\n1E(i) 32.30(3.3) 0.9144(0.040) 77.02 0.8833(0.0085) 0.8469(0.050) 0.8612(0.021) 0.8821(0.014)\\nLD 32.28(3.3) 0.8976(0.038) 95.91 0.8893(0.0086) 0.8522(0.050) 0.8687(0.021) 0.8897(0.012)\\nLHRL 32.78(3.3) 0.9230(0.037) 78.02 0.8899(0.0082) 0.8532(0.050) 0.8693(0.021) 0.8890(0.013)\\nvariations. Narrowing the distance between the feature maps of the ﬁrst encoder block (i.e. LE(1)) in the segmentation U-Net is an\\neﬀective restriction of pixel-wise and structure reconstruction, leading to an increase of PSNR and SSIM scores. On the other hand,\\ndecreasing the dice coe ﬃcient of the predicted labels (i.e. LHRL) and the distance between the output of decoders (i.e. LD) help\\nsemantic information recovery, leading to better segmentation performance. For example, the model ﬁne-tuned with LHRLachieves\\nthe best dice scores of the whole brain, the grey matter and the white matter and the second best dice score of the CSF with a slight\\ndecline of PSNR and SSIM. Meanwhile, the experiments show that outputs of both ends in the U-Net are more useful for the SR\\ntask, but the feature maps of hidden layers seem useless. Perceptual losses based on the feature maps of the second to the ﬁfth\\nencoder block neither increase the PSNR and SSIM scores nor improve the segmentation performance.\\nSR for humans or machines? In addition to the distortion-perception trade-o ﬀof SR results, we ﬁnd a human and machine\\nperceptual di ﬀerence in the experiments of perceptual losses. we admit that both PSNR and SSIM are essential for SR image evalu-\\nation of ﬁdelity. However, neither can represent human perception or the performance in potential downstream image analysis tasks.\\nSimilarly, Fr ´echet Inception distance (FID [Heusel et al. (2018)]) has been used in previous works of medical image analysis tasks\\n[Yi et al. (2019); Kazeminia et al. (2020)] to evaluate the perceptual quality. However, its signiﬁcance for medical images is also\\ndoubtful because the metric is designed for and pre-trained with natural images. In clinics, medical images are mainly for doctors\\nto view and for machines to auto analysis. However, it is hard to explain how PSNR, SSIM and FID represent the perceptual per-\\nformance in both cases. Inspired by [Xia et al. (2021)], we take segmentation as a typical downstream task to discuss the di ﬀerence\\nbetween human perception (with FID) and machine perception (with dice coe ﬃcients) of super-resolved medical images. Based\\non the conclusions and discussions in previous works [Zhu et al. (2021b)], we agree that PSNR and SSIM represent the ﬁdelity of\\nSR images and assume that FID denotes human perception quality. Additionally, we take the segmentation dice coe ﬃcient scores\\nas the measurement for machine perception. In general, PSNR and SSIM closely correspond, but they are independent with either\\nFID or dice scores. There is a trade-o ﬀbetween these three aspects, and none of the models can achieve superior performance in\\nmore than two directions. Thus, we suggest SR models be customised to suit the particular task. For example, the RDST variant\\nﬁne-tuned withLE(1)is proper for general purpose, and the variations ﬁne-tuned with LVGGandLWGANGP are recommended for\\nhuman viewing. Furthermore, we suggest using the segmentation label-based loss LHRLfor SR model ﬁne-tuning to meet the\\nparticular needs of downstream segmentation tasks.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='06afae8c-0030-4a29-abe1-575348f48f0d', embedding=None, metadata={'page_label': '21', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 21\\nTable 7. Fine-tuning RDST variations with LHRLand comparing with SOTA methods in the downstream segmentation tasks. The mean and standard\\ndeviations of the dice coe ﬃcients of the whole organs (e.g. brain or tumour) of SR results are compared. The best and the second best scores are\\nhighlighted in red and blue, respectively, while ∗indicates better segmentation performance than HR ground truth images. Red and green cells indicate\\nimproved and declined scores compared to LE(1), respectively.\\nDice-T /WT↑HR Bicubic EDSR RCAN RDST-E(LE(1)) RDST(LE(1))\\nOASIS 0.9520(0.012) 0.8125(0.0088) 0.8784(0.0098) 0.8828(0.0094) 0.8871(0.0096) 0.8889(0.0097)\\nBraTS 0.7833(0.13) 0.7614(0.12) 0.7800(0.12) 0.7815(0.12) 0.7831(0.12) 0.7836*(0.12)\\nACDC 0.8932(0.027) 0.8096(0.051) 0.8599(0.030) 0.8657(0.030) 0.8691(0.025) 0.8691(0.027)\\nCOVID-CT 0.8762(0.11) 0.8092(0.12) 0.8315(0.18) 0.8365(0.17) 0.8264(0.19) 0.8445(0.16)\\nDice-T /WT↑ RDN HAN SwinIR RDST-E(LHRL) RDST(LHRL)\\nOASIS 0.8802(0.010) 0.8751(0.0091) 0.8888(0.0097) 0.8899(0.0082) 0.8906(0.0081)\\nBraTS 0.7806(0.12) 0.7801(0.12) 0.7836*(0.12) 0.7825(0.13) 0.7842*(0.13)\\nACDC 0.8624(0.029) 0.8666(0.030) 0.8705(0.026) 0.8745(0.024) 0.8732(0.024)\\nCOVID-CT 0.8196(0.19) 0.8323(0.18) 0.8299(0.18) 0.8347(0.18) 0.8411(0.16)\\nTable 8. Dice coe ﬃcients of each tissue in the downstream segmentation tasks of SR results. RDST variations (ﬁne-tuned with LHRL) and one SOTA method\\nwith the best performance are compared for each dataset. The highest scores are highlighted in red.\\nOASIS Dice-T↑ Dice-G↑ Dice-W↑ Dice-CSF↑\\nSwinIR 0.8888(0.0097) 0.8506(0.054) 0.8688(0.020) 0.8880(0.015)\\nRDST-E(LHRL)0.8899(0.0082) 0.8532(0.050) 0.8693(0.021) 0.8890(0.013)\\nRDST(LHRL) 0.8906(0.0081) 0.8567(0.049) 0.8693(0.021) 0.8885(0.013)\\nBraTS Dice-WT↑ Dice-ET↑ Dice-TC↑\\nSwinIR 0.7836(0.12) 0.6816(0.12) 0.6710(0.16)\\nRDST-E(LHRL)0.7825(0.13) 0.7039(0.12) 0.6922(0.17)\\nRDST(LHRL) 0.7842(0.13) 0.6970(0.12) 0.6869(0.17)\\nACDC Dice-T↑ Dice-LV↑ Dice-RV↑ Dice-MC↑\\nSwinIR 0.8705(0.026) 0.9001(0.043) 0.6964(0.12) 0.8456(0.039)\\nRDST-E(LHRL)0.8745(0.024) 0.9005(0.044) 0.7068(0.12) 0.8501(0.032)\\nRDST(LHRL) 0.8732(0.024) 0.8996(0.036) 0.7197(0.11) 0.8476(0.036)\\nCOVID-CT Dice-T↑ Dice-LL↑ Dice-RL↑ Dice-Lesion↑\\nRCAN 0.8365(0.17) 0.8175(0.21) 0.8684(0.13) 0.6207(0.11)\\nRDST-E(LHRL)0.8347(0.18) 0.8237(0.21) 0.8632(0.14) 0.5974(0.097)\\nRDST(LHRL) 0.8411(0.16) 0.8265(0.20) 0.8585(0.15) 0.6173(0.089)\\nSR for segmentation we ﬁne-tune RDST and RDST-E with LHRLand both models achieve superior segmentation performance\\nthan SOTA methods on all datasets (Table. 7). Compared with LE(1)ﬁne-tuned RDST variants, the RDST-E (with LHRL) improves\\nthe segmentation performance of the whole regions in the experiments with the OASIS, the ACDC and the COVID-CT datasets and\\nincreases the dice coe ﬃcient scores by 0.0040 on average of all four datasets, while the RDST (with LHRL) improves the segmen-\\ntation performance on the OASIS, the BraTS and the ACDC datasets and increases the dice coe ﬃcient scores by 0.0008 on average\\nof all four datasets. In addition, we choose one SOTA method with the best segmentation performance for each dataset and compare\\nit with theLHRLﬁne-tuned RDST variants in detail (Table. 8). Among the 15 sub-regions in total, both RDST and RDST-E (with\\nLHRL) achieve the best scores on 7 sub-regions (with one overlap) and RCAN achieves the best segmentation performance of the\\nright lung and lesion of the COVID-CT dataset.\\nExtending to SOTA methods The proposed segmentation-based perceptual loss variations can successfully extend to other SOTA\\nmethods (Tabel. 9 and Fig. 11). To verify the universality and usability, LE1andLHRLare used to ﬁne-tune three popular SOTA\\nSISR methods, including CNNs and vision transformers: RDN [Zhang et al. (2018b)], RCAN [Zhang et al. (2018a)] and SwinIR\\n[Liang et al. (2021)]. In contrast to the baselines (trained with L1for 100k steps), extra training steps with only L1bring limited', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='3db6d5c0-52fc-4dc3-b55c-10f189fd7962', embedding=None, metadata={'page_label': '22', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='22 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nFig. 11. Extend the segmentation based perceptual loss variations LE(1)andLHRLto three popular SOTA methods: RDN Zhang et al. (2018b), RCAN\\nZhang et al. (2018a) and SwinIR Liang et al. (2021). For each method, three ﬁne-tuned variations (with L1,LE(1)andLHRL, respectively) are compared\\nwith the baseline (trained for 100k steps with L1only).\\nimprovements of PSNR ( +0.04 dB) and segmentation performance ( +0.0005 Dice-T /WT) on average. Conversely, the proposed\\nsegmentation-based perceptual loss variations signiﬁcantly boost both image quality ( +0.16 dB PSNR on average with LE(1)) and\\nsegmentation accuracy ( +0.0028 Dice-T /WT on average with LHRL). Similar to the above conclusion in this section, models ﬁned-\\ntuned withLHRLachieve the best dice scores in the downstream segmentation tasks in all cases, as expected. On the other hand,\\nmodels ﬁne-tuned with LE1achieve the best PSNR for all cases and the second-best dice scores in most cases.\\nTo datasets without segmentation labels In the above experiments, the segmentation-based perceptual loss LE(1)has demonstrated\\nits robust applicability and e ﬀectiveness. In most cases, it signiﬁcantly improves image ﬁdelity quality (i.e. PSNR and SSIM) with\\ncomparable segmentation performance. Although we train a segmentation model for each dataset independently, the training is not\\na limitation. To use LE(1), a U-Net can be trained on one dataset with segmentation labels and straightly extended to a new dataset\\nwithout segmentation labels. In the simulation experiment, we use the pre-trained U-Net models with the OASIS, the ACDC and\\nthe COVID-CT datasets to ﬁne-tune the RDST-E model of every dataset and achieve equal performance (Table. 10). Compared\\nwith the baselines (120k steps training with L1), they result in obvious improvement of PSNR and dice coe ﬃcient scores in almost\\nall cases. The prior knowledge of the pre-trained segmentation model with one medical image dataset can be e ﬀectively transferred\\nto new datasets. Proposed segmentation perceptual loss LE(1)can become regular in a wider range of medical image low-level tasks.\\n5.4. Limitations and future works\\nAlthough the above experiments illustrate the superior performance and robustness of the proposed method, three limitations are\\nworth to be noticed. First of all, all results and comparisons are achieved in simulation SR tasks. The degradation and noise formu-\\nlation we used for HR-LR image pair generation in Section 4.1 may not represent the actual condition of various medical modalities\\nin the clinic. Thus, it is worth exploring the capacity of the proposed method in enhancement tasks with clinical medical images in\\nthe future. Second, it is challenging to avoid over-ﬁtting in medical image SR tasks. In Section 5.1, the proposed method RDST\\nachieves the best performance (i.e. PSNR) for three datasets but achieves worse performance than the lite version RDST-E with\\nthe small dataset ACDC. we deduce that the decline is caused by over-ﬁtting because fewer training steps of regular-size models', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='7377eeb1-9dbc-4015-a769-b585c7f87881', embedding=None, metadata={'page_label': '23', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 23\\nTable 9. Extending the proposed segmentation-based perceptual losses to SOTA methods. For each method, the baseline model is trained with L1only for\\n100k steps. Three ﬁne-tuned variations are additionally trained for 20k steps with: (1) L1only; (2)L1withLE(1); and (3)L1withLHRL. In each group of\\nthe same method, the best and the second-best scores are in highlighted in red and blue, respectively.\\nModel Training PSNR↑ SSIM↑ Dice-T↑ Dice-G↑ Dice-W↑ Dice-CSF↑\\n100k-L1 32.57(3.2) 0.9241(0.036) 0.8802(0.010) 0.8316(0.059) 0.8620(0.021) 0.8845(0.015)\\n+20k-L1 32.62(3.3) 0.9217(0.037) 0.8810(0.010) 0.8343(0.058) 0.8621(0.021) 0.8840(0.015)\\n+20k-LE(1) 32.78(3.4) 0.9227(0.037) 0.8815(0.0099) 0.8361(0.058) 0.8622(0.021) 0.8830(0.014)RDN\\n+20k-LHRL 32.30(3.1) 0.9153(0.038) 0.8843(0.0088) 0.8440(0.052) 0.8640(0.021) 0.8859(0.014)\\n100k-L1 32.81(3.6) 0.9224(0.038) 0.8828(0.0094) 0.8424(0.054) 0.8619(0.021) 0.8831(0.013)\\n+20k-L1 32.81(3.6) 0.9221(0.038) 0.8827(0.0094) 0.8419(0.055) 0.8619(0.021) 0.8828(0.013)\\n+20k-LE(1) 32.94(3.7) 0.9231(0.038) 0.8833(0.0093) 0.8432(0.054) 0.8623(0.021) 0.8836(0.014)RCAN\\n+20k-LHRL 32.64(3.5) 0.9187(0.038) 0.8851(0.0082) 0.8477(0.050) 0.8637(0.021) 0.8841(0.013)\\n100k-L1 33.24(3.7) 0.9287(0.036) 0.8888(0.0097) 0.8506(0.054) 0.8688(0.020) 0.8880(0.015)\\n+20k-L1 33.33(3.7) 0.9295(0.036) 0.8891(0.010) 0.8523(0.054) 0.8688(0.021) 0.8872(0.015)\\n+20k-LE(1) 33.46(3.7) 0.9303(0.036) 0.8893(0.011) 0.8521(0.054) 0.8692(0.021) 0.8874(0.015)SwinIR\\n+20k-LHRL 33.08(3.6) 0.9248(0.037) 0.8908(0.0086) 0.8573(0.048) 0.8697(0.021) 0.8899(0.014)\\n100k-L1 33.25(3.5) 0.9286(0.035) 0.8880(0.0097) 0.8489(0.055) 0.8679(0.021) 0.8881(0.015)\\n+20k-L1 33.29(3.6) 0.9293(0.035) 0.8890(0.0094) 0.8512(0.054) 0.8690(0.020) 0.8877(0.015)\\n+20k-LE(1) 33.42(3.7) 0.9299(0.035) 0.8889(0.0097) 0.8514(0.054) 0.8688(0.021) 0.8874(0.015)RDST\\n+20k-LHRL 33.01(3.5) 0.9243(0.037) 0.8906(0.0081) 0.8567(0.049) 0.8693(0.021) 0.8885(0.013)\\n(e.g. RDST and SwinIR) result in higher PSNR scores in the experiments of ACDC. Thus, developing data-driven early-stopping\\nmethods [Ying (2019)] for each case of medical image dataset is necessary and signiﬁcant. Third, in the ablation study of model\\neﬃciency (Section 5.2), vision transformers are much slower in inference than CNN models with similar sizes. Although RDST\\nvariants have achieved the smallest model size and fewest parameters, non-attention CNN methods (i.e. EDSR and RDN) are still\\nmore than twice faster as our proposed method. Exploring more e ﬃcient vision transformers [Rao et al. (2021); Tang et al. (2022a)]\\nwith the remaining SR performance will be very interesting.\\nAdditional feature works can also be arranged in the following two directions. On the one hand, the proposed method can be\\na potential backbone for broader low-level medical image analysis tasks. For example, the residual dense vision transformer can\\nbe extended to MR and CT synthesis [Wolterink et al. (2017)] tasks with shallow feature extraction and up-sampler layers modiﬁ-\\ncations. Meanwhile, the proposed perceptual losses can be alternatives in MR imaging reconstruction and image registration [Xue\\net al. (2022); Han et al. (2022)]. On the other hand, super-resolution tasks can be integrated into more downstream medical image\\nanalysis tasks than segmentation. Thus, the proposed method can be introduced to more medical modalities in addition to radiology\\nscans. For example, novel perceptual losses may be designed with pre-trained models of retinal image classiﬁcation [Playout et al.\\n(2022)] and improve the performance of retinal image synthesis [Zhao et al. (2018)].\\n6. Conclusion\\nIn this work, we aim to improve the single-image super-resolution performance and e ﬃciency of supervised vision transformers\\non medical images by introducing popular mechanisms in previous CNNs to transformers and transferring prior knowledge of\\nsegmentation tasks to SR tasks. We present an e ﬃcient and robust single-image super-resolution method for medical images by\\nsuccessfully introducing the residual dense connection and local feature fusion to vision transformers. This developed RDST and its\\neﬃcient version RDST-E have achieved superior or equal performance to the SOTA SISR methods of both SR image ﬁdelity quality\\nand downstream auto segmentation tasks. In the simulation experiments of four public medical image datasets, including MR and\\nCT scans, the proposed approaches have resulted in averaged improvements of +0.09 dB and +0.06 dB PSNR receptively with only', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='5d82e54b-7969-42c5-a260-3c4e1c218451', embedding=None, metadata={'page_label': '24', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='24 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nTable 10. A transfer learning study on the segmentation-based perceptual loss in the ﬁne-tuning stage. For each testing dataset of OASIS, ACDC and\\nCOVID, the RDST is trained for 120k steps with only L1as the baselines to avoid the impacts of extra training steps. In the ﬁne-tuning stage, pre-trained\\nU-Net models with OASIS, ACDC and COVID datasets are used respectively to calculate LE(1). Scores in red indicate better performance than baselines,\\nand scores in green indicate worse performance.\\nTesting Baseline Which U-Net for LE(1)\\nPSNR↑ 120k-L1 OASIS ACDC COVID\\nOASIS 33.12(3.4) 33.26(3.4) 33.27(3.4) 33.26(3.4)\\nACDC 27.23(3.0) 27.24(3.0) 27.24(3.0) 27.24(3.0)\\nCOVID 34.58(4.4) 34.60(4.4) 34.62(4.4) 34.62(4.5)\\nDice-T↑120k-L1 OASIS ACDC COVID\\nOASIS 0.8874(0.0094) 0.8871(0.0096) 0.8874(0.0094) 0.8875(0.0094)\\nACDC 0.8681(0.026) 0.8684(0.025) 0.8691(0.025) 0.8683(0.025)\\nCOVID 0.8241(0.19) 0.8284(0.18) 0.8301(0.18) 0.8264(0.19)\\n38% and 20% parameters of SwinIR. Meanwhile, we implement a perceptual loss for SR tasks based on the prior knowledge of pre-\\ntrained segmentation models and successfully extend its variants to SOTA methods, including CNNs and ViTs. The perceptual loss\\nvariant for reconstruction ﬁdelity has led to an improvement of +0.14 dB PSNR on average, and the variant for machine perception\\n(i.e. downstream segmentation tasks) has led to an improvement of 0.0023 dice coe ﬃcient on average. In summary, this work has\\nintroduced a framework with novel and practical designs on model architecture, loss function, training tricks and evaluation metrics.\\nIt has achieved SOTA performance in super-resolution tasks with various medical image modalities. It is also a potential backbone\\nfor more medical image low-level tasks such as reconstruction and synthesis.\\nAcknowledgments\\nJin Zhu was supported by China Scholarship Council (201708060173). Guang Yang was supported in part by the BHF (TG /18/5/34111,\\nPG/16/78/32402), the ERC IMI (101005122), the H2020 (952172), the MRC (MC /PC/21013), the Royal Society (IEC /NSFC /211235),\\nand the UKRI Future Leaders Fellowship (MR /V023799 /1).\\nReferences\\nAnwar, S., Barnes, N., 2020. Densely residual laplacian super-resolution. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 1192–1204.\\nArjovsky, M., Chintala, S., Bottou, L., 2017. Wasserstein gan. arXiv:1701.07875 .\\nBakas, S., Akbari, H., Sotiras, A., Bilello, M., Rozycki, M., Kirby, J., et al., 2017. Advancing the cancer genome atlas glioma mri collections with expert\\nsegmentation labels and radiomic features. Scientiﬁc Data 4. doi: 10.1038/sdata.2017.117 .\\nBakas, S., Reyes, M., Jakab, A., Bauer, S., Rempﬂer, M., Crimi, A., et al., 2018. Identifying the best machine learning algorithms for brain tumor segmentation,\\nprogression assessment, and overall survival prediction in the BRATS challenge. CoRR abs /1811.02629. URL: http://arxiv.org/abs/1811.02629 ,\\narXiv:1811.02629 .\\nBell, S., Upchurch, P., Snavely, N., Bala, K., 2015. Material recognition in the wild with the materials in context database. arXiv:1412.0623 .\\nBernard, O., Lalande, A., Zotti, C., Cervenansky, F., Yang, X., Heng, P.A., Cetin, I., Lekadir, K., Camara, O., Ballester, M.A.G., et al., 2018. Deep learning\\ntechniques for automatic mri cardiac multi-structures segmentation and diagnosis: is the problem solved? IEEE transactions on medical imaging 37, 2514–2525.\\nBhandary, M., Reyes, J.P., Ertay, E., Panda, A., 2022. Double u-net for super-resolution and segmentation of live cell images. arXiv preprint arXiv:2212.02028 .\\nBrody, H., 2013. Medical imaging. Nature 502, S81–S81.\\nCao, H., Wang, Y ., Chen, J., Jiang, D., Zhang, X., Tian, Q., Wang, M., 2021. Swin-unet: Unet-like pure transformer for medical image segmentation. arXiv preprint\\narXiv:2105.05537 .\\nCastillo-Barnes, D., Martinez-Murcia, F.J., Ortiz, A., Salas-Gonzalez, D., Ram ´Irez, J., G ´orriz, J.M., 2020. Morphological characterization of functional brain\\nimaging by isosurface analysis in parkinson’s disease. International journal of neural systems 30, 2050044–2050044.\\nCavaro-Menard, C., Zhang, L., Le Callet, P., 2010. Diagnostic quality assessment of medical images: Challenges and trends, in: 2010 2nd European Workshop on\\nVisual Information Processing (EUVIP), pp. 277–284. doi: 10.1109/EUVIP.2010.5699147 .\\nChan, H.P., Samala, R.K., Hadjiiski, L.M., Zhou, C., 2020. Deep learning in medical image analysis. Deep Learning in Medical Image Analysis , 3–21.\\nChandler, D.M., 2013. Seven challenges in image quality assessment: past, present, and future research. International Scholarly Research Notices 2013.\\nChen, H., Wang, Y ., Guo, T., Xu, C., Deng, Y ., Liu, Z., Ma, S., Xu, C., Xu, C., Gao, W., 2021. Pre-trained image processing transformer, in: Proceedings of the\\nIEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 12299–12310.\\nChen, Y ., Shi, F., Christodoulou, A.G., Zhou, Z., Xie, Y ., Li, D., 2018a. E ﬃcient and accurate mri super-resolution using a generative adversarial network and 3d\\nmulti-level densely connected network. arXiv:1803.01417 .\\nChen, Y ., Xie, Y ., Zhou, Z., Shi, F., Christodoulou, A.G., Li, D., 2018b. Brain mri super resolution using 3d deep densely connected neural networks, in: 2018 IEEE\\n15th international symposium on biomedical imaging (ISBI 2018), IEEE. pp. 739–742.\\nChoi, J.S., Kim, M., 2017. A deep convolutional neural network with selection units for super-resolution, in: Proceedings of the IEEE conference on computer\\nvision and pattern recognition workshops, pp. 154–160.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='38f9ceb9-9a32-49b6-9414-0e08d5b96702', embedding=None, metadata={'page_label': '25', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 25\\nChow, L.S., Paramesran, R., 2016. Review of medical image quality assessment. Biomedical signal processing and control 27, 145–154.\\nDai, T., Cai, J., Zhang, Y ., Xia, S.T., Zhang, L., 2019. Second-order attention network for single image super-resolution, in: Proceedings of the IEEE /CVF\\nconference on computer vision and pattern recognition, pp. 11065–11074.\\nDeng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L., 2009. Imagenet: A large-scale hierarchical image database, in: 2009 IEEE conference on computer\\nvision and pattern recognition, Ieee. pp. 248–255.\\nDing, X., Zhang, X., Han, J., Ding, G., 2022. Scaling up your kernels to 31x31: Revisiting large kernel design in cnns, in: Proceedings of the IEEE /CVF Conference\\non Computer Vision and Pattern Recognition, pp. 11963–11975.\\nDong, C., Loy, C.C., He, K., Tang, X., 2015. Image super-resolution using deep convolutional networks. IEEE transactions on pattern analysis and machine\\nintelligence 38, 295–307.\\nDong, C., Loy, C.C., Tang, X., 2016. Accelerating the super-resolution convolutional neural network, in: Computer Vision–ECCV 2016: 14th European Conference,\\nAmsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part II 14, Springer. pp. 391–407.\\nDu, J., He, Z., Wang, L., Gholipour, A., Zhou, Z., Chen, D., Jia, Y ., 2020. Super-resolution reconstruction of single anisotropic 3d mr images using residual\\nconvolutional neural network. Neurocomputing 392, 209–220.\\nFan, C.M., Liu, T.J., Liu, K.H., 2022. Sunet: Swin transformer unet for image denoising. arXiv preprint arXiv:2202.14009 .\\nFang, J., Lin, H., Chen, X., Zeng, K., 2022. A hybrid network of cnn and transformer for lightweight image super-resolution, in: Proceedings of the IEEE /CVF\\nConference on Computer Vision and Pattern Recognition, pp. 1103–1112.\\nde Farias, E.C., Di Noia, C., Han, C., Sala, E., Castelli, M., Rundo, L., 2021. Impact of gan-based lesion-focused medical image super-resolution on the robustness\\nof radiomic features. Scientiﬁc reports 11, 21361.\\nGao, G., Wang, Z., Li, J., Li, W., Yu, Y ., Zeng, T., 2022. Lightweight bimodal network for single-image super-resolution via symmetric cnn and recursive transformer.\\narXiv preprint arXiv:2204.13286 .\\nGreenspan, H., Oz, G., Kiryati, N., Peled, S., 2002. Mri inter-slice reconstruction using super-resolution. Magnetic resonance imaging 20, 437–446.\\nGu, Y ., Zeng, Z., Chen, H., Wei, J., Zhang, Y ., Chen, B., Li, Y ., Qin, Y ., Xie, Q., Jiang, Z., et al., 2020. Medsrgan: medical images super-resolution using generative\\nadversarial networks. Multimedia Tools and Applications 79, 21815–21840.\\nGulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V ., Courville, A.C., 2017. Improved training of wasserstein gans. Advances in neural information processing\\nsystems 30, 5767–5777.\\nGuo, M.H., Xu, T.X., Liu, J.J., Liu, Z.N., Jiang, P.T., Mu, T.J., Zhang, S.H., Martin, R.R., Cheng, M.M., Hu, S.M., 2022a. Attention mechanisms in computer\\nvision: A survey. Computational Visual Media 8, 331–368.\\nGuo, P., Mei, Y ., Zhou, J., Jiang, S., Patel, V .M., 2022b. Reconformer: Accelerated mri reconstruction using recurrent transformer. arXiv preprint arXiv:2201.09376\\n.\\nHan, K., Wang, Y ., Chen, H., Chen, X., Guo, J., Liu, Z., Tang, Y ., Xiao, A., Xu, C., Xu, Y ., et al., 2020. A survey on visual transformer. arXiv preprint\\narXiv:2012.12556 2.\\nHan, R., Jones, C.K., Lee, J., Wu, P., Vagdargi, P., Uneri, A., Helm, P.A., Luciano, M., Anderson, W.S., Siewerdsen, J.H., 2022. Deformable mr-ct image registration\\nusing an unsupervised, dual-channel network for neurosurgical guidance. Medical image analysis 75, 102292.\\nHan, W., Chang, S., Liu, D., Yu, M., Witbrock, M., Huang, T.S., 2018. Image super-resolution via dual-state recurrent networks, in: Proceedings of the IEEE\\nconference on computer vision and pattern recognition, pp. 1654–1663.\\nHe, K., Gan, C., Li, Z., Rekik, I., Yin, Z., Ji, W., Gao, Y ., Wang, Q., Zhang, J., Shen, D., 2022a. Transformers in medical image analysis: A review. arXiv preprint\\narXiv:2202.12165 .\\nHe, K., Zhang, X., Ren, S., Sun, J., 2015a. Deep residual learning for image recognition. arXiv:1512.03385 .\\nHe, K., Zhang, X., Ren, S., Sun, J., 2015b. Delving deep into rectiﬁers: Surpassing human-level performance on imagenet classiﬁcation. arXiv:1502.01852 .\\nHe, X., Zhou, Y ., Zhao, J., Zhang, D., Yao, R., Xue, Y ., 2022b. Swin transformer embedding unet for remote sensing image semantic segmentation. IEEE\\nTransactions on Geoscience and Remote Sensing 60, 1–15.\\nHendrycks, D., Gimpel, K., 2016. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415 .\\nHenry, E.U., Emebob, O., Omonhinmin, C.A., 2022. Vision transformers in medical imaging: A review. arXiv preprint arXiv:2211.10043 .\\nHeusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., Hochreiter, S., 2018. Gans trained by a two time-scale update rule converge to a local nash equilibrium.\\narXiv:1706.08500 .\\nHo, J., Saharia, C., Chan, W., Fleet, D.J., Norouzi, M., Salimans, T., 2022. Cascaded di ﬀusion models for high ﬁdelity image generation. J. Mach. Learn. Res. 23,\\n1–33.\\nHu, X., Mu, H., Zhang, X., Wang, Z., Tan, T., Sun, J., 2019. Meta-sr: A magniﬁcation-arbitrary network for super-resolution, in: Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition, IEEE. pp. 1575–1584.\\nHuang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017. Densely connected convolutional networks, in: Proceedings of the IEEE conference on computer\\nvision and pattern recognition, pp. 4700–4708.\\nHuang, J., Fang, Y ., Wu, Y ., Wu, H., Gao, Z., Li, Y ., Del Ser, J., Xia, J., Yang, G., 2022. Swin transformer for fast mri. Neurocomputing 493, 281–304.\\nHui, Z., Wang, X., Gao, X., 2018. Fast and accurate single image super-resolution via information distillation network, in: Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition, pp. 723–731.\\nIakubovskii, P., 2019. Segmentation models pytorch. https://github.com/qubvel/segmentation_models.pytorch .\\nIoﬀe, S., Szegedy, C., 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 .\\nIsaac, J.S., Kulkarni, R., 2015. Super resolution techniques for medical image processing, in: 2015 International Conference on Technologies for Sustainable\\nDevelopment (ICTSD), IEEE. pp. 1–6.\\nJang, S.I., Pan, T., Li, G.Y ., Chen, J., Li, Q., Gong, K., 2022. Pet image denoising based on transformer: evaluations on datasets of multiple tracers.\\nJiang, M., Zhi, M., Wei, L., Yang, X., Zhang, J., Li, Y ., Wang, P., Huang, J., Yang, G., 2021. Fa-gan: Fused attentive generative adversarial networks for mri image\\nsuper-resolution. Computerized Medical Imaging and Graphics 92, 101969.\\nJiang, X., Liu, M., Zhao, F., Liu, X., Zhou, H., 2020. A novel super-resolution ct image reconstruction via semi-supervised generative adversarial network. Neural\\nComputing and Applications 32, 14563–14578.\\nJohnson, J., Alahi, A., Fei-Fei, L., 2016. Perceptual losses for real-time style transfer and super-resolution. arXiv:1603.08155 .\\nKazeminia, S., Baur, C., Kuijper, A., van Ginneken, B., Navab, N., Albarqouni, S., Mukhopadhyay, A., 2020. Gans for medical image analysis. Artiﬁcial Intelligence\\nin Medicine 109, 101938.\\nKim, J., Kwon Lee, J., Mu Lee, K., 2016. Accurate image super-resolution using very deep convolutional networks, in: Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition, IEEE. pp. 1646–1654.\\nKim, J., Lee, J.K., Lee, K.M., 2015. Deeply-recursive convolutional network for image super-resolution. CoRR abs /1511.04491. URL: http://arxiv.org/abs/\\n1511.04491 ,arXiv:1511.04491 .\\nKingma, D.P., Ba, J., 2014. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 .\\nLedig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., Shi, W., 2017. Photo-realistic single image', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='a7f5dfa8-8e05-4299-b7b7-2ee7b55a35c0', embedding=None, metadata={'page_label': '26', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text=\"26 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nsuper-resolution using a generative adversarial network. arXiv:1609.04802 .\\nLeming, M., G ´orriz, J.M., Suckling, J., 2020. Ensemble deep learning on large, mixed-site fmri datasets in autism and other tasks. International journal of neural\\nsystems 30, 2050012.\\nLepcha, D.C., Goyal, B., Dogra, A., Goyal, V ., 2022. Image super-resolution: A comprehensive review, recent trends, challenges and applications. Information\\nFusion .\\nLi, G., Lv, J., Tian, Y ., Dou, Q., Wang, C., Xu, C., Qin, J., 2022a. Transformer-empowered multi-scale contextual matching and aggregation for multi-contrast mri\\nsuper-resolution, in: Proceedings of the IEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 20636–20645.\\nLi, H., Yang, Y ., Chang, M., Chen, S., Feng, H., Xu, Z., Li, Q., Chen, Y ., 2022b. Srdi ﬀ: Single image super-resolution with di ﬀusion probabilistic models.\\nNeurocomputing 479, 47–59.\\nLi, J., Fang, F., Mei, K., Zhang, G., 2018. Multi-scale residual network for image super-resolution, in: Proceedings of the European conference on computer vision\\n(ECCV), pp. 517–532.\\nLi, Y ., Iwamoto, Y ., Lin, L., Xu, R., Tong, R., Chen, Y .W., 2021a. V olumenet: a lightweight parallel network for super-resolution of mr and ct volumetric data.\\nIEEE Transactions on Image Processing 30, 4840–4854.\\nLi, Y ., Sixou, B., Peyrin, F., 2021b. A review of the deep learning methods for medical images super resolution problems. Irbm 42, 120–133.\\nLiang, J., Cao, J., Sun, G., Zhang, K., Van Gool, L., Timofte, R., 2021. Swinir: Image restoration using swin transformer, in: Proceedings of the IEEE /CVF\\nInternational Conference on Computer Vision, pp. 1833–1844.\\nLim, B., Son, S., Kim, H., Nah, S., Lee, K.M., 2017. Enhanced deep residual networks for single image super-resolution. arXiv:1707.02921 .\\nLitjens, G., Kooi, T., Bejnordi, B.E., Setio, A.A.A., Ciompi, F., Ghafoorian, M., Van Der Laak, J.A., Van Ginneken, B., S ´anchez, C.I., 2017. A survey on deep\\nlearning in medical image analysis. Medical image analysis 42, 60–88.\\nLiu, J., Zhang, W., Tang, Y ., Tang, J., Wu, G., 2020. Residual feature aggregation network for image super-resolution, in: Proceedings of the IEEE /CVF conference\\non computer vision and pattern recognition, pp. 2359–2368.\\nLiu, P., Zhang, H., Zhang, K., Lin, L., Zuo, W., 2018. Multi-level wavelet-cnn for image restoration, in: Proceedings of the IEEE conference on computer vision\\nand pattern recognition workshops, pp. 773–782.\\nLiu, Z., Lin, Y ., Cao, Y ., Hu, H., Wei, Y ., Zhang, Z., Lin, S., Guo, B., 2021. Swin transformer: Hierarchical vision transformer using shifted windows, in:\\nProceedings of the IEEE /CVF International Conference on Computer Vision, pp. 10012–10022.\\nLiu, Z., Mao, H., Wu, C.Y ., Feichtenhofer, C., Darrell, T., Xie, S., 2022. A convnet for the 2020s, in: Proceedings of the IEEE /CVF Conference on Computer Vision\\nand Pattern Recognition, pp. 11976–11986.\\nLu, Z., Li, J., Liu, H., Huang, C., Zhang, L., Zeng, T., 2022. Transformer for single image super-resolution, in: Proceedings of the IEEE /CVF Conference on\\nComputer Vision and Pattern Recognition, pp. 457–466.\\nLuo, W., Li, Y ., Urtasun, R., Zemel, R., 2016. Understanding the e ﬀective receptive ﬁeld in deep convolutional neural networks. Advances in neural information\\nprocessing systems 29.\\nLyu, Q., Shan, H., Steber, C., Helis, C., Whitlow, C., Chan, M., Wang, G., 2020. Multi-contrast super-resolution mri through a progressive network. IEEE\\ntransactions on medical imaging 39, 2738–2749.\\nLyu, Q., You, C., Shan, H., Wang, G., 2018. Super-resolution mri through deep learning. arXiv preprint arXiv:1810.06776 .\\nMa, J., Chen, J., Ng, M., Huang, R., Li, Y ., Li, C., Yang, X., Martel, A.L., 2021a. Loss odyssey in medical image segmentation. Medical Image Analysis 71,\\n102035.\\nMa, J., Wang, Y ., An, X., Ge, C., Yu, Z., Chen, J., Zhu, Q., Dong, G., He, J., He, Z., et al., 2021b. Toward data-e ﬃcient learning: A benchmark for covid-19 ct lung\\nand infection segmentation. Medical physics 48, 1197–1210.\\nManj ´on, J.V ., Coup ´e, P., Buades, A., Collins, D.L., Robles, M., 2010. Mri superresolution using self-similarity and image priors. Journal of Biomedical Imaging\\n2010, 1–11.\\nMarcus, D.S., Wang, T.H., Parker, J., Csernansky, J.G., Morris, J.C., Buckner, R.L., 2007. Open access series of imaging studies (oasis): cross-sectional mri data in\\nyoung, middle aged, nondemented, and demented older adults. Journal of cognitive neuroscience 19, 1498–1507.\\nMcDonagh, S., Hou, B., Alansary, A., Oktay, O., Kamnitsas, K., Rutherford, M., Hajnal, J.V ., Kainz, B., 2017. Context-sensitive super-resolution for fast fetal mag-\\nnetic resonance imaging, in: Molecular Imaging, Reconstruction and Analysis of Moving Body Organs, and Stroke Imaging and Treatment: Fifth International\\nWorkshop, CMMI 2017, Second International Workshop, RAMBO 2017, and First International Workshop, SWITCH 2017, Held in Conjunction with MICCAI\\n2017, Qu ´ebec City, QC, Canada, September 14, 2017, Proceedings 5, Springer. pp. 116–126.\\nMehri, A., Ardakani, P.B., Sappa, A.D., 2021. Mprnet: Multi-path residual network for lightweight image super resolution, in: Proceedings of the IEEE /CVF Winter\\nConference on Applications of Computer Vision, pp. 2704–2713.\\nMenze, B.H., Jakab, A., Bauer, S., Kalpathy-Cramer, J., Farahani, K., Kirby, J., et al., 2015. The multimodal brain tumor image segmentation benchmark (brats).\\nIEEE Transactions on Medical Imaging 34, 1993–2024. doi: 10.1109/TMI.2014.2377694 .\\nMilletari, F., Navab, N., Ahmadi, S.A., 2016. V-net: Fully convolutional neural networks for volumetric medical image segmentation, in: 2016 fourth international\\nconference on 3D vision (3DV), IEEE. pp. 565–571.\\nMirzaei, G., Adeli, A., Adeli, H., 2016. Imaging and machine learning techniques for diagnosis of alzheimer’s disease. Reviews in the Neurosciences 27, 857–870.\\nMirzaei, G., Adeli, H., 2016. Resting state functional magnetic resonance imaging processing techniques in stroke studies. Reviews in the Neurosciences 27,\\n871–885.\\nNiu, B., Wen, W., Ren, W., Zhang, X., Yang, L., Wang, S., Zhang, K., Cao, X., Shen, H., 2020. Single image super-resolution via a holistic attention network, in:\\nEuropean conference on computer vision, Springer. pp. 191–207.\\nOktay, O., Bai, W., Lee, M., Guerrero, R., Kamnitsas, K., Caballero, J., de Marvao, A., Cook, S., O’Regan, D., Rueckert, D., 2016. Multi-input cardiac image\\nsuper-resolution using convolutional neural networks, in: Medical Image Computing and Computer-Assisted Intervention-MICCAI 2016: 19th International\\nConference, Athens, Greece, October 17-21, 2016, Proceedings, Part III 19, Springer. pp. 246–254.\\nOktay, O., Ferrante, E., Kamnitsas, K., Heinrich, M., Bai, W., Caballero, J., Cook, S.A., De Marvao, A., Dawes, T., O’Regan, D.P., et al., 2017. Anatomically\\nconstrained neural networks (acnns): application to cardiac image enhancement and segmentation. IEEE transactions on medical imaging 37, 384–395.\\nOzsahin, I., Sekeroglu, B., Musa, M.S., Mustapha, M.T., Ozsahin, D.U., 2020. Review on diagnosis of covid-19 from chest ct images using artiﬁcial intelligence.\\nComputational and Mathematical Methods in Medicine 2020.\\nPark, J., Hwang, D., Kim, K.Y ., Kang, S.K., Kim, Y .K., Lee, J.S., 2018. Computed tomography super-resolution using deep convolutional neural network. Physics\\nin Medicine & Biology 63, 145011.\\nPaszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf,\\nA., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., Chintala, S., 2019. Pytorch: An impera-\\ntive style, high-performance deep learning library, in: Wallach, H., Larochelle, H., Beygelzimer, A., d'Alch ´e-Buc, F., Fox, E., Garnett, R. (Eds.),\\nAdvances in Neural Information Processing Systems 32. Curran Associates, Inc., pp. 8024–8035. URL: http://papers.neurips.cc/paper/\\n9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf .\\nPeled, S., Yeshurun, Y ., 2001. Superresolution in mri: application to human white matter ﬁber tract visualization by di ﬀusion tensor imaging. Magnetic Resonance\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='ed3df4ad-8722-4d3f-a558-83e0ae90e695', embedding=None, metadata={'page_label': '27', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023) 27\\nin Medicine: An O ﬃcial Journal of the International Society for Magnetic Resonance in Medicine 45, 29–35.\\nPham, C.H., Ducournau, A., Fablet, R., Rousseau, F., 2017. Brain mri super-resolution using deep 3d convolutional networks, in: 2017 IEEE 14th International\\nSymposium on Biomedical Imaging (ISBI 2017), IEEE. pp. 197–200.\\nPlayout, C., Duval, R., Boucher, M.C., Cheriet, F., 2022. Focused attention in transformers for interpretable classiﬁcation of retinal images. Medical Image Analysis\\n82, 102608.\\nPuttaguntaa, M., Subbanb, R., Cc, N.K.B., 2022. Swinir transformer applied for medical image super-resolution. Procedia Computer Science 204, 907–913.\\nQiu, D., Cheng, Y ., Wang, X., 2021. Progressive u-net residual network for computed tomography images super-resolution in the screening of covid-19. Journal of\\nRadiation Research and Applied Sciences 14, 369–379.\\nQiu, D., Cheng, Y ., Wang, X., 2022. Dual u-net residual networks for cardiac magnetic resonance images super-resolution. Computer Methods and Programs in\\nBiomedicine 218, 106707.\\nRao, Y ., Zhao, W., Liu, B., Lu, J., Zhou, J., Hsieh, C.J., 2021. Dynamicvit: E ﬃcient vision transformers with dynamic token sparsiﬁcation. Advances in neural\\ninformation processing systems 34, 13937–13949.\\nRen, H., El-Khamy, M., Lee, J., 2017. Image super resolution based on fusing multiple convolution neural networks, in: Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition workshops, pp. 54–61.\\nRonneberger, O., Fischer, P., Brox, T., 2015. U-net: Convolutional networks for biomedical image segmentation. arXiv:1505.04597 .\\nRousseau, F., 2008. Brain hallucination, in: Computer Vision–ECCV 2008: 10th European Conference on Computer Vision, Marseille, France, October 12-18,\\n2008, Proceedings, Part I 10, Springer. pp. 497–508.\\nS´anchez, I., Vilaplana, V ., 2018. Brain mri super-resolution using 3d generative adversarial networks. arXiv preprint arXiv:1812.11440 .\\nShahidi, F., 2021. Breast cancer histopathology image super-resolution using wide-attention gan with improved wasserstein gradient penalty and perceptual loss.\\nIEEE Access 9, 32795–32809.\\nShen, D., Wu, G., Suk, H.I., 2017. Deep learning in medical image analysis. Annual review of biomedical engineering 19, 221.\\nShi, J., Li, Z., Ying, S., Wang, C., Liu, Q., Zhang, Q., Yan, P., 2018. Mr image super-resolution via wide residual networks with ﬁxed skip connection. IEEE journal\\nof biomedical and health informatics 23, 1129–1140.\\nShi, W., Caballero, J., Husz ´ar, F., Totz, J., Aitken, A.P., Bishop, R., Rueckert, D., Wang, Z., 2016. Real-time single image and video super-resolution using an\\neﬃcient sub-pixel convolutional neural network. arXiv:1609.05158 .\\nShilling, R.Z., Robbie, T.Q., Bailloeul, T., Mewes, K., Mersereau, R.M., Brummer, M.E., 2008. A super-resolution framework for 3-d high-resolution and high-\\ncontrast imaging using 2-d multislice mri. IEEE transactions on medical imaging 28, 633–644.\\nShocher, A., Cohen, N., Irani, M., 2017. ”zero-shot” super-resolution using deep internal learning. arXiv:1712.06087 .\\nTai, Y ., Yang, J., Liu, X., 2017a. Image super-resolution via deep recursive residual network, in: Proceedings of the IEEE conference on computer vision and pattern\\nrecognition, pp. 3147–3155.\\nTai, Y ., Yang, J., Liu, X., Xu, C., 2017b. Memnet: A persistent memory network for image restoration, in: Proceedings of the IEEE international conference on\\ncomputer vision, pp. 4539–4547.\\nTang, Y ., Han, K., Wang, Y ., Xu, C., Guo, J., Xu, C., Tao, D., 2022a. Patch slimming for e ﬃcient vision transformers, in: Proceedings of the IEEE /CVF Conference\\non Computer Vision and Pattern Recognition, pp. 12165–12174.\\nTang, Y ., Yang, D., Li, W., Roth, H.R., Landman, B., Xu, D., Nath, V ., Hatamizadeh, A., 2022b. Self-supervised pre-training of swin transformers for 3d medical\\nimage analysis, in: Proceedings of the IEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 20730–20740.\\nTong, T., Li, G., Liu, X., Gao, Q., 2017. Image super-resolution using dense skip connections, in: Proceedings of the IEEE International Conference on Computer\\nVision, IEEE. pp. 4799–4807.\\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, Ł., Polosukhin, I., 2017. Attention is all you need. Advances in neural\\ninformation processing systems 30.\\nWang, X., Yu, K., Wu, S., Gu, J., Liu, Y ., Dong, C., Qiao, Y ., Change Loy, C., 2018. Esrgan: Enhanced super-resolution generative adversarial networks, in:\\nProceedings of the European Conference on Computer Vision (ECCV), Springer Science +Business Media. pp. 0–0.\\nWang, Z., Bovik, A.C., 2009. Mean squared error: Love it or leave it? a new look at signal ﬁdelity measures. IEEE signal processing magazine 26, 98–117.\\nWang, Z., Chen, J., Hoi, S.C., 2020. Deep learning for image super-resolution: A survey. IEEE transactions on pattern analysis and machine intelligence .\\nWang, Z., Cun, X., Bao, J., Zhou, W., Liu, J., Li, H., 2022. Uformer: A general u-shaped transformer for image restoration, in: Proceedings of the IEEE /CVF\\nConference on Computer Vision and Pattern Recognition, pp. 17683–17693.\\nWolterink, J.M., Dinkla, A.M., Savenije, M.H., Seevinck, P.R., van den Berg, C.A., I ˇsgum, I., 2017. Deep mr to ct synthesis using unpaired data, in: International\\nworkshop on simulation and synthesis in medical imaging, Springer. pp. 14–23.\\nXia, Y ., Ravikumar, N., Greenwood, J.P., Neubauer, S., Petersen, S.E., Frangi, A.F., 2021. Super-resolution of cardiac mr cine imaging using conditional gans and\\nunsupervised transfer learning. Medical Image Analysis 71, 102037.\\nXue, S., Cheng, Z., Han, G., Sun, C., Fang, K., Liu, Y ., Cheng, J., Jin, X., Bai, R., 2022. 2d probabilistic undersampling pattern optimization for mr image\\nreconstruction. Medical Image Analysis 77, 102346.\\nYang, Q., Yan, P., Zhang, Y ., Yu, H., Shi, Y ., Mou, X., Kalra, M.K., Zhang, Y ., Sun, L., Wang, G., 2018. Low-dose ct image denoising using a generative adversarial\\nnetwork with wasserstein distance and perceptual loss. IEEE transactions on medical imaging 37, 1348–1357.\\nYang, W., Zhang, X., Tian, Y ., Wang, W., Xue, J.H., Liao, Q., 2019. Deep learning for single image super-resolution: A brief review. IEEE Transactions on\\nMultimedia 21, 3106–3121. URL: http://dx.doi.org/10.1109/TMM.2019.2919431 , doi: 10.1109/tmm.2019.2919431 .\\nYi, X., Walia, E., Babyn, P., 2019. Generative adversarial network in medical imaging: A review. Medical image analysis 58, 101552.\\nYing, X., 2019. An overview of overﬁtting and its solutions, in: Journal of physics: Conference series, IOP Publishing. p. 022022.\\nYou, C., Li, G., Zhang, Y ., Zhang, X., Shan, H., Li, M., Ju, S., Zhao, Z., Zhang, Z., Cong, W., et al., 2019. Ct super-resolution gan constrained by the identical,\\nresidual, and cycle learning ensemble (gan-circle). IEEE transactions on medical imaging 39, 188–203.\\nYou, S., Lei, B., Wang, S., Chui, C.K., Cheung, A.C., Liu, Y ., Gan, M., Wu, G., Shen, Y ., 2022. Fine perceptive gans for brain mr image super-resolution in wavelet\\ndomain. IEEE transactions on neural networks and learning systems .\\nZamir, S.W., Arora, A., Khan, S., Hayat, M., Khan, F.S., Yang, M.H., 2022. Restormer: E ﬃcient transformer for high-resolution image restoration, in: Proceedings\\nof the IEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 5728–5739.\\nZhai, G., Min, X., 2020. Perceptual image quality assessment: a survey. Science China Information Sciences 63, 1–52.\\nZhang, Y ., Li, K., Li, K., Wang, L., Zhong, B., Fu, Y ., 2018a. Image super-resolution using very deep residual channel attention networks. arXiv:1807.02758 .\\nZhang, Y ., Tian, Y ., Kong, Y ., Zhong, B., Fu, Y ., 2018b. Residual dense network for image super-resolution, in: Proceedings of the IEEE conference on computer\\nvision and pattern recognition, IEEE. pp. 2472–2481.\\nZhao, H., Li, H., Maurer-Stroh, S., Cheng, L., 2018. Synthesizing retinal and neuronal images with generative adversarial nets. Medical image analysis 49, 14–26.\\nZhao, L., Wang, J., Li, X., Tu, Z., Zeng, W., 2016. Deep convolutional neural networks with merge-and-run mappings. arXiv preprint arXiv:1611.07718 .\\nZhao, X., Zhang, Y ., Zhang, T., Zou, X., 2019. Channel splitting network for single mr image super-resolution. IEEE transactions on image processing 28,\\n5649–5662.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
              " Document(id_='0bef4b8d-d69b-4338-99be-4fdcd13bad8f', embedding=None, metadata={'page_label': '28', 'file_name': '2302.11184.pdf', 'file_path': '/content/data/2302.11184.pdf', 'file_type': 'application/pdf', 'file_size': 7077831, 'creation_date': '2024-02-01', 'last_modified_date': '2024-02-01', 'last_accessed_date': '2024-02-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='28 Jin Zhu et al. /Preprint submitted to Medical Image Analysis (2023)\\nZhou Wang, Bovik, A.C., Sheikh, H.R., Simoncelli, E.P., 2004. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image\\nProcessing 13, 600–612. doi: 10.1109/TIP.2003.819861 .\\nZhu, H., Xie, C., Fei, Y ., Tao, H., 2021a. Attention mechanisms in cnn-based single image super-resolution: A brief review and a new perspective. Electronics 10,\\n1187.\\nZhu, J., Tan, C., Yang, J., Yang, G., Lio’, P., 2021b. Arbitrary scale super-resolution for medical images. International Journal of Neural Systems 31, 2150037.\\nZhu, J., Yang, G., Lio, P., 2018. Lesion focused super-resolution. arXiv:1810.06693 .\\nZhu, J., Yang, G., Lio, P., 2019. How can we make gan perform better in single medical image super-resolution? a lesion focused multi-scale approach. 2019 IEEE\\n16th International Symposium on Biomedical Imaging (ISBI 2019) URL: http://dx.doi.org/10.1109/ISBI.2019.8759517 , doi: 10.1109/isbi.2019.\\n8759517 .\\nZhu, J.Y ., Park, T., Isola, P., Efros, A.A., 2020. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv:1703.10593 .\\nZou, W., Ye, T., Zheng, W., Zhang, Y ., Chen, L., Wu, Y ., 2022. Self-calibrated e ﬃcient transformer for lightweight super-resolution, in: Proceedings of the\\nIEEE /CVF Conference on Computer Vision and Pattern Recognition, pp. 930–939.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n",
        "## Default format supportable by LLama2\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ],
      "metadata": {
        "id": "sk-DoBA_TJh_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlnOmdt_UVf5",
        "outputId": "474d667c-7f6b-4b0f-9afa-0b7ab0f969db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate HuggingFaceLLM:\n",
        "\n",
        "This creates an instance of the HuggingFaceLLM class, connecting to the Llama-2 model hosted on Hugging Face.\n",
        "Key configuration parameters:\n",
        "\n",
        "context_window=4096: The maximum number of tokens the model can consider in a single context.\n",
        "\n",
        "max_new_tokens=256: The maximum length of generated responses.\n",
        "\n",
        "generate_kwargs: Controls text generation behavior (temperature=0.0 for deterministic responses, do_sample=False to avoid randomness).\n",
        "\n",
        "system_prompt: Sets the overall task framing for the model (Q&A assistant).\n",
        "\n",
        "query_wrapper_prompt: Formats user queries with placeholders (<|USER|>, <|ASSISTANT|>).\n",
        "\n",
        "tokenizer_name and model_name: Specify the tokenizer and language model to use (Llama-2-7b-chat-hf).\n",
        "\n",
        "device_map=\"auto\": Automatically chooses CPU or GPU based on availability.\n",
        "\n",
        "model_kwargs: Optional settings for memory optimization on CUDA devices (torch_dtype=torch.float16, load_in_8bit=True)"
      ],
      "metadata": {
        "id": "n2StLYxJVC7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "de399a6cba674bb59afc0f6741fdd7cd",
            "680144a3d559460db1cd633bc9e83ab4",
            "b917ad74f03a4fc897a678b37dc992b1",
            "bb40242536a2430a996166d63fb70d21",
            "a0101392287e49d98281c2e0ed885790",
            "0f853601783848898c44a5a34d4e091b",
            "10874f14c1c149e28adf7622b1d0879f",
            "728e1a55c81641d98f79240151626dcf",
            "32a43da0e6864c31b37a9b81a821d9f1",
            "a413df1921b449668c6bc4533a8efad3",
            "1cd7e035b98f4e508edc2de8584db8fe",
            "74aa1e12c1a54fabb2a15ea423a271b2",
            "68f1ed72e3b24d7c91014932b933e53e",
            "017c323842d444b0a1890f386f77e7c2",
            "2d9207e8c4bc46e4839d835f5805c4fb",
            "8607a4e547f347dca04a7b4abc13ad8f",
            "eb9739700bac47bca5bb95c5e9c9a9d8",
            "db58f0abed6e4534b3c1064ac808fa13",
            "cbbad5b04d71463ea2ed80a0db31d2c1",
            "06b6c50c482b4766897a6bc55e08137a",
            "a49302bb18fd4b87baae99b56273f9c5",
            "c0924730a7304634877bff5c328a19c6",
            "534b4970f73d4f41b399e6860ecd5d9d",
            "2800c6ddcba14a388540d038d9ebe3b3",
            "dc8c8cb1100048a799836459e1e24c9b",
            "b05587a6dca5441ba4761ea0dfa47482",
            "f8a29890aa0642a7b409fd6a42016e3a",
            "f2a2bd2c929344f7964c1841a3594bb1",
            "1014241257804129b29985b2136e934b",
            "f48bfe038b614f399959cec81998302a",
            "91c91a94e2a4410a85732ce8b93e4a09",
            "f472a4d6eab140059543028d65655286",
            "678413217fe643d6a12451796d8d353d",
            "ad0c6c2353fd4622bb2d9ef25db5f1a4",
            "d91efaa66d784de29813c413c75db84b",
            "ba8b3d5b1f1249008c81f2e2f41cc414",
            "54eb08aebfdf4993bb76cda80bb22eab",
            "e1631c625c4b4bd5b1d4277473301153",
            "0a54133b4b4e40b6a6778003b1924ecd",
            "518f6e299b1b4b5f8932fd89f751970b",
            "b634e4b03d6649eba991c7ad83885ef6",
            "9f45570dc9fc457fa340f6e23ad35050",
            "d5d86b90822b4f0887ed1e1b42ed8384",
            "20be6e7471da4003a4a7e172c0deb575",
            "73f930df3d7849029cf5aee69521abf8",
            "7e569bb0c749439c8bbc6cc20b398523",
            "d83598db074345a0871c1c15b3f4cd06",
            "1b35db9614ed41e092ab7cf923df6b02",
            "126544b500fa49a68ad7279f00f7fb8e",
            "db602f0c40dc42d5909131ac428a5afe",
            "2e3f5a48f7394481bf5806fe0deb160c",
            "e62527da123f4eae9de6f5a283de7d6e",
            "72a11a9ac9d04ca69b7555da8117f1bb",
            "283cc415a2004d4d9dbe581c24fb69f4",
            "54698ad9566046148d8911e27ec7e770",
            "deffb4e3d2464afab7e9de0903561688",
            "e2fcf6d71a4e4ffbad10bb2dc718218a",
            "e3b628c4bc7c400caf5e5f79ac08d4b9",
            "a78f52a2ccf04e718548360a554bc894",
            "2853bd3d62414a49a26d11c0dd9f094b",
            "54d1113ce20148858ec3c575b9d5150d",
            "83e9c74958ef458a878ac7694cbd568f",
            "80a3713f77a646d19937129308ffb6d2",
            "922254dfdd8543aa8fc39474431f4d2d",
            "5d12a19245f84932a5d3af264a8ed41e",
            "d44d4b4eadb74db0998a229e74b8eaec",
            "96bbd8087838489b8b1af943386e90a7",
            "4ae0c617d58647ec9d06cdc0ae7b1970",
            "3bc9359bffc941509d6b246ffd7042eb",
            "1ce6f82add9c41668aadf8bedaed20ef",
            "7b637d455b90415e964116e0558b853a",
            "da71cbe6eb314708b14905a4493cde9f",
            "477a87b2312c46b897f5b7ee00b2cbd1",
            "5d7eec731ed24473bc9388ef065885e0",
            "48512e4e784f456e9e4b70a865aed74f",
            "1dcd1b72cbe347b096dd002d1482d578",
            "d1e74a04cae942c586472d6cb8fd5c56",
            "452084d132174bc3a752394aab247094",
            "21286ffdeec84668b0d577f80ff9ca0b",
            "50cd16b2b2b14a128506cf46aba1a5e2",
            "20d113ad05ac489f980fc883fc28ceba",
            "272dfb48b1984fb0ae40fc4d60f0153d",
            "f6e1ead30aa74e5b9a571e3bc653cfd7",
            "534917c5ee4a4e73bf06d57ca8421ea0",
            "79936272eff841b79a582e0cfb8576ce",
            "974972f126174be2964ccb8dc973bf74",
            "ddb08032f66148398bc527181230b09b",
            "a6ce20adf74a44049f0baa74ab8e0b4b",
            "2fc5300ac2a641bfb0af35c0c88fb369",
            "b71dbc6b2fc749fbae21c21ba9692747",
            "79fd470180cf46ceb0f8dd0fac09a695",
            "cd4dc0b201e14a71984eb2867a554c3c",
            "0442d33020e94a35b197f7cff01d84e5",
            "f561d767a64a441fa97a6d919b28dbe7",
            "74ea1251252a44c8b2be486504e7e33a",
            "cd2b98fe37444f9a9e8973699426e035",
            "317f6a4a34d84848af11381e3860ee81",
            "6a98913bfe104891bfdbc7b0ae0ea738",
            "8439dd823b5a41ce8586a0feb29314c1",
            "06ad2688f7a84251bc3464a5af4082c6",
            "68fcb5a41ca04414b3f80d447a0ca1e5",
            "521e2d82af0944dbbe11ad06798e1c25",
            "3cc44ba1d9bb4ffba9c1807e144c7764",
            "d21f670ea40f4048a11d55c75b7b5c39",
            "088d2ced8591472ab8db9716cdc0a40b",
            "9a12cb97b49147daa96847ad86718edc",
            "4702b5ed833849c88a43bf8bba887165",
            "565f8869e8c94697a55ea112ca6b4c8c",
            "9ce073da5ae147a6b409fcb6475347f3",
            "278f4d2f89714725bf7480a6fd3d7112",
            "e42ae020374240048e9c9437fec73b18",
            "a150c6b9ac994ae7bd644a8b6f316c1e",
            "5d5d147750274c7dbbb8a9e4e6d75c45",
            "4bd946625f3045af923cdcb9e6f32945",
            "ababef2ce6544671aa53a33db2c91ab7",
            "4dd916c6d52c45058eb489a2a5c916ca",
            "b7ad0d71e1eb4b7bbdc47d5e4dc0aceb",
            "6b2db8a7363745ff98cc3945931971cc",
            "ab8f0158c9404617bc95f8913ee1b6de",
            "3f60855cdeec4d8e97a023faeef3e699",
            "6fe3477054dd48d7a6422a3a82dba648"
          ]
        },
        "id": "LbiLDT3yUn_-",
        "outputId": "e71d96ac-bcba-4e8e-b77c-c4462c4182e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de399a6cba674bb59afc0f6741fdd7cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74aa1e12c1a54fabb2a15ea423a271b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "534b4970f73d4f41b399e6860ecd5d9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad0c6c2353fd4622bb2d9ef25db5f1a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73f930df3d7849029cf5aee69521abf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deffb4e3d2464afab7e9de0903561688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96bbd8087838489b8b1af943386e90a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "452084d132174bc3a752394aab247094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fc5300ac2a641bfb0af35c0c88fb369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06ad2688f7a84251bc3464a5af4082c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e42ae020374240048e9c9437fec73b18"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import necessary classes:\n",
        "\n",
        "HuggingFaceEmbeddings (from langchain.embeddings.huggingface): Accesses embedding models from Hugging Face.\n",
        "ServiceContext and LangchainEmbedding (from llama_index): Manage service configurations and create embeddings for indexing.\n",
        "2. Instantiate LangchainEmbedding:\n",
        "\n",
        "Wraps a HuggingFaceEmbeddings model to make it compatible with llama_index.\n",
        "Specifies model_name=\"sentence-transformers/all-mpnet-base-v2\": Uses a multi-purpose sentence transformer model for text embedding.\n",
        "Key concepts:\n",
        "\n",
        "Embeddings: Dense vectors that capture semantic meaning of text, enabling similarity comparisons and retrieval.\n",
        "HuggingFaceEmbeddings: Provides access to various embedding models on Hugging Face.\n",
        "LangchainEmbedding: Adapts embedding models for use within llama_index.\n",
        "sentence-transformers/all-mpnet-base-v2: A versatile model trained on multi-lingual text for various semantic tasks."
      ],
      "metadata": {
        "id": "D4-wEREZZyNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import ServiceContext\n",
        "from llama_index.embeddings import LangchainEmbedding\n",
        "\n",
        "embed_model=LangchainEmbedding(\n",
        "    HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "ccb53e553fc24f00bc1c40fb1fe92af7",
            "2f47c1b60a8141d2b83cba704b582f28",
            "700625e9fbf34fc3a4be0e1aca0f7b9e",
            "8ef902858f2840848a386fdde9c549f4",
            "8d52a8ef58204ab38c52502e0c5991ac",
            "01815c9026444a44bbefce0fe267f19a",
            "da39c542307c493c8d5fe2f0176f621e",
            "9c4d8b856d11497092eec506d29ad4b9",
            "7d7e75958f82415c8e4315ad5c8d6467",
            "9a0a43a8adc14b9382056c542d47ac98",
            "9ccab893491d4005ad3340cd0be4bd16",
            "c38d42d62713431e9bba7321976fd18a",
            "bd6f9459a2ce4dc9aeaebfee1430f538",
            "9f5876b16b3d4237927293c6aa1c6da4",
            "bde4106190a0456992c6a08a739e277f",
            "cf1986b3024942f8a2a83c0797234d54",
            "43fecb87f3d3405da939727ba4f7c40a",
            "747ef7faaabe44f1a041c883bf80ee3b",
            "cff464dd6e124d2fac0926704a380057",
            "4f2ddc69003c43dbb22e65d5830178e9",
            "9a248b8ac4934021a8eccc0ded7dffbc",
            "9388eda4a9e84e168cf1259d44931647",
            "9209b0f270134ac0881bd9e1f81cdd7b",
            "71e28164e7f349d3b1c468f5a333a0c7",
            "fdad79c5e73644bda129a024ee2329c3",
            "f5b83a80b0a64662a7300ea76892b6a4",
            "3fb924fec95243949704e76a9dd71cb4",
            "5b48d118e15948a6bc3744d12d0fc296",
            "8dce746006b04a029ea2f19897d501f5",
            "58ea0f1345cd4007b43a602f9d3be86d",
            "981893b157314816a8fab3fc7008b684",
            "608c1ffbac514019b6a16eab857dfb79",
            "7cb11490e47c495b886fb772da2beae9",
            "0d1116535d2d4110a5dd1638d9dc51d8",
            "f6ecc007721d4c3a81a801a43d7d3873",
            "7d96895580de4cafa2e120420eb602de",
            "c032324d38b9435d922880dceb2c0076",
            "9815ba2b6f71456aa54dea35156d0499",
            "8e99fc049cd04717a3d07cdd86617709",
            "1a7987542eb24e2fbebef9222ed91bf1",
            "c051adc33fbb46508ef3384243e0e7c0",
            "0f0bd7ef23cd4af297acb371f2fad71d",
            "83e8dd13b21a461cb92291c9cd2ae26b",
            "5fc79d8f5f2d423b816f61023a5fdc02",
            "5c90140b5e5d4bc2842bc18edcd930bc",
            "3f942f90634e4e36822d445ab8f14f14",
            "af9c7fc9a9f744299e92367a0071c535",
            "6cc1b88d77ef42208ee5496caf07fdf6",
            "a3ef89fb98024446a996434cba468850",
            "b5059e37e036479384a6f3d2aeb001c9",
            "e4d3fec8e11f4d7faae2ff9075b6b8a3",
            "9bbfdbcafb7e4460849a67f811313362",
            "17730a0210b34d479cf89a7e26583d8f",
            "9d4ce0bce2774f198253cb5297c864a4",
            "d2d97f78081149308a14a9823c439faa",
            "5efcb7ec4d5941728564946c3bb906d2",
            "5b848a41a84e47648d1a5b2eb66a2989",
            "3b5e5ef62d4c42f89ff76f64442b74ac",
            "38cdd751528b42efb0ef120cd15455a3",
            "e20e86e628234a34b4d4db8fb86f9924",
            "cda51a0ac7864410a3004b81a04f101c",
            "539bcf849ef9400fa473cfa60bb1754d",
            "d04cc9e8dd9440fa9180849a8dabefd0",
            "332fac6a24f044309ac8b7ecab2bf061",
            "032c467d9d1641f1b7e263cdfd242965",
            "74c956e1883d48028cb5c095255b4309",
            "aa26813a662a4a33bd0f1f97ad10bce9",
            "d355cf43582142b4832147cd2f97a0fe",
            "acca279e24ea4573b6bddb547e67ca8f",
            "22bf0f04042c4d1794dc543d1cf6bdb9",
            "549a948008464aa1afdca7ac890bb672",
            "e09747f345f447d2b8caa67bbff5b621",
            "d4037678d47f4cfaaaae0827ffee592e",
            "f7b4ecffc8334f8b9416631a7de8b609",
            "afb42a97e477411cb891fe3c866eef68",
            "5e6129429b534764906aacf812ca0d01",
            "dad94799475e48fa804797e5a609ad9d",
            "bdcb2e50e2954179a56710297f8c1119",
            "2580b501dcb944c5a9bcd79cda686b8d",
            "1402cf0d59964a4098f7bb01ef453f03",
            "e4561e58b3914540a10ce7114795655e",
            "25a467bb6df64c589dbce36abb925e09",
            "d8b57b9c2f8a47a9ac0a19b4da8a1915",
            "7878a7cb58874314b9fed5ddd04108b2",
            "25cb0a57b7e04705b76ad6135482005a",
            "9981379aca0e4772b87120da5a307390",
            "06089cba177444678b9014c613ca6171",
            "ca2c78ff92594d0eaaef00ae9f8f2a47",
            "1154f972d6664eba99b1ea73c926c85b",
            "caac90c8a099434fbd7c6bccd18e4263",
            "21ee94c063e348eca7078ecc303ce99d",
            "6e20ca45f01446cd8277f31cf43851ae",
            "921f1bc43812425dacdfb262ac0d12f3",
            "b79199d7b7274ace9ff8233922979879",
            "7ac7e32cc4e14e22a692180fcc35b624",
            "d4da545ae8014645a54607530549dd69",
            "1eab02a9a1dc4159b0e37bc051c5623c",
            "3c4900b8cb014b20a8f5678b4ed9441f",
            "f0d8e820d9fd48b49ae4f586fe02a650",
            "a42395df5019409f8c32d7b0a54294e6",
            "f7661e755b40455fa80c8832865f7932",
            "bc00fff5eb764e8fac0e05772b05ff59",
            "0c92e0a349af44a18587c5ab9154461c",
            "ea8beb99424d43229674c30d3f80ca84",
            "6b3e401b5db347b0a074ee61d7109c06",
            "6c81bb36eb984433bfa7efc889e79761",
            "f1de512c68a64760b7545a954d4b0888",
            "9df640a16bbe46ecad999c4d27300cf0",
            "38e0ebeb04b145fd96d594f94dce303b",
            "0b4471f3ab9242e98c00dbade4327857",
            "fff1cd270ce24b7f933f76b030fe4c68",
            "653482970e214f23aa66b72caade4027",
            "9451c8ec3f844a71813b4848876fb78e",
            "97cd03aa548a499f9bc790656e977ad9",
            "27e4c247d2194e49b0c30c36c8a3c277",
            "f23a9b058aed4bac8f0d540516dba585",
            "9e82e62818a04c2dae0e82a5d6f797a4",
            "7368af9e5ec04a6c9a3fbdc9bbf2d6e1",
            "1a4f66807baa4929875eef49f45c95de",
            "be2d94b090e547deab6d8cbf42788b26",
            "153b4585aa574ed18c453e031c187b54"
          ]
        },
        "id": "6nlVXvMCUw5o",
        "outputId": "cb80467b-77b5-400d-89ad-f24f55639d1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccb53e553fc24f00bc1c40fb1fe92af7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c38d42d62713431e9bba7321976fd18a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9209b0f270134ac0881bd9e1f81cdd7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d1116535d2d4110a5dd1638d9dc51d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c90140b5e5d4bc2842bc18edcd930bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5efcb7ec4d5941728564946c3bb906d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa26813a662a4a33bd0f1f97ad10bce9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdcb2e50e2954179a56710297f8c1119"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1154f972d6664eba99b1ea73c926c85b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a42395df5019409f8c32d7b0a54294e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fff1cd270ce24b7f933f76b030fe4c68"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_context=ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ],
      "metadata": {
        "id": "MU6yLV5WZglF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_context"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho6wA1oPZm8M",
        "outputId": "7360145d-100c-4fec-cf1a-897879e94781"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=4096, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=LangchainEmbedding(model_name='sentence-transformers/all-mpnet-base-v2', embed_batch_size=10, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7c55b6fcbc10>), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7c55b6fcbc10>, id_func=<function default_id_func at 0x7c56a55463b0>, chunk_size=1024, chunk_overlap=200, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.logger.base.LlamaLogger object at 0x7c55b6fcbac0>, callback_manager=<llama_index.callbacks.base.CallbackManager object at 0x7c55b6fcbc10>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index=VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
        ""
      ],
      "metadata": {
        "id": "lTxtiE2laDDa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJNN2kTUaGjF",
        "outputId": "25fdb97e-67cb-4e21-ac07-936061186eaf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.base.VectorStoreIndex at 0x7c56a51e8d30>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine=index.as_query_engine()\n",
        ""
      ],
      "metadata": {
        "id": "ywYbZoEGaHXP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(\"what is A residual dense vision transformer for medical image super-resolution with segmentation-based perceptual loss fine-tuning?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYrd5GmAaKn2",
        "outputId": "1d520225-6191-44ef-c5a0-9337ffaadf56"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5bmKc4qaSMN",
        "outputId": "ad67f566-0345-4179-d3cb-95f82d4ec01c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A residual dense vision transformer for medical image super-resolution with segmentation-based perceptual loss fine-tuning is a type of deep learning model that uses a combination of residual connections and local feature fusion to improve the quality of super-resolved medical images. The model is based on a vision transformer architecture, which is a type of neural network that is particularly well-suited for image processing tasks. The segmentation-based perceptual loss fine-tuning is a technique that uses prior knowledge of medical image segmentation to improve the quality of the super-resolved images. By combining these techniques, the model is able to produce high-quality super-resolved medical images with improved segmentation accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N2pXpiChad0j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}